[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Janine De Vera",
    "section": "",
    "text": "Hello, my name is Janine   Data Scientist and Economic Researcher  Berlin, Germany\n\n\n\n\n\nAbout me, my interests, and my work as a data scientist and researcher\n\n\nABOUT\n\n\n\n\n\n\n\n\nShort posts about pasts projects and current research interests\n\n\nPORTFOLIO\n\n\n\n\n\n\n\n\nDatasets I’ve processed and made available for public use\n\n\nDATASETS\n\n\n\n\n\n\n\n\nWhere to find me online. Would love to get in touch!\n\n\nCONTACT"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About\n\n\nWelcome to my personal website! My name is Janine and I am a data scientist and economic researcher based in Berlin, Germany. I hold a MSc in Data Science from Hertie School and a BS in Economics from the University of the Philippines. I have over seven years of professional experience in quantitative data analysis with organizations such as the Asian Development Bank, the United Nations Development Programme, and the Philippine Competition Commission.\nI specialize in Natural Language Processing (NLP) for public policy with a focus on text classification and named entity recognition in domain-specific text. This has use cases ranging from the detection of anti-competitive provisions in draft legislation to the parsing of SDG compliance reports. As most human data is textual in nature, I believe NLP is key to understanding the world we live in.\nMy programming language of choice is Python  and . I also have some familiarity with SQL.\n\nIn my past work, I have traveled to countries like Kazakhstan and Türkiye to conduct workshops with government officials on national accounting and input-output global value chain analysis.\nOutside of work, I am an aerial arts and pole dance enthusiast."
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "About Me",
    "section": "",
    "text": "MSc Data Science for Public Policy  Hertie School, 2021-2023  Berlin, Germany \nBS Business Economics  University of the Philippines Diliman, 2010-2014  Manila, Philippines"
  },
  {
    "objectID": "about.html#experience",
    "href": "about.html#experience",
    "title": "Janine De Vera",
    "section": "Experience",
    "text": "Experience"
  },
  {
    "objectID": "portfolio.html",
    "href": "portfolio.html",
    "title": "Portfolio",
    "section": "",
    "text": "Portfolio\nHere I talk about some research endeavors and projects I’ve done in the past - in school, at work, or just out of curiousity.\n\n\n\n\n\n\n\n\n\n\n\n\n\nMigration Sentiment Monitor\n\n\nI created a web application that tracks sentiment scores in migration related news from Reuters.\n\n\n\n\n\n\nJul 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUsing AI to Detect Anti-Competitive Legislation\n\n\nI build a legal text classifier that correctly identifies up to 98% of paragraphs with potentially problematic provisions.\n\n\n\n\n\n\nMay 13, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFriendly Countries Make Deep Trade Agreements\n\n\nThrough network analysis, I find that deep trade agreements are less about economics and more about politics\n\n\n\n\n\n\nMay 1, 2023\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/thesis.html",
    "href": "posts/thesis.html",
    "title": "Thesis",
    "section": "",
    "text": "Insert text here"
  },
  {
    "objectID": "posts/post1.html",
    "href": "posts/post1.html",
    "title": "Post 1",
    "section": "",
    "text": "Hello"
  },
  {
    "objectID": "posts/post1/post1.html",
    "href": "posts/post1/post1.html",
    "title": "Post 1",
    "section": "",
    "text": "Hello"
  },
  {
    "objectID": "posts/04 climate/index.html",
    "href": "posts/04 climate/index.html",
    "title": "Climate",
    "section": "",
    "text": "Image"
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Contact",
    "section": "",
    "text": "Let’s connect!\nHere’s where you can find me online:\n          \nYou can also drop me an e-mail at janinepdevera@gmail.com"
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Janine De Vera",
    "section": "",
    "text": "MSc Data Science for Public Policy  Hertie School, 2021-2023  Berlin, Germany \nBS Business Economics  University of the Philippines Diliman, 2010-2014  Manila, Philippines"
  },
  {
    "objectID": "resume.html#education",
    "href": "resume.html#education",
    "title": "Janine De Vera",
    "section": "",
    "text": "MSc Data Science for Public Policy  Hertie School, 2021-2023  Berlin, Germany \nBS Business Economics  University of the Philippines Diliman, 2010-2014  Manila, Philippines"
  },
  {
    "objectID": "resume.html#experience",
    "href": "resume.html#experience",
    "title": "Janine De Vera",
    "section": "Experience",
    "text": "Experience"
  },
  {
    "objectID": "posts/03 climate/index.html",
    "href": "posts/03 climate/index.html",
    "title": "Climate",
    "section": "",
    "text": "Image"
  },
  {
    "objectID": "datasets.html",
    "href": "datasets.html",
    "title": "Datasets",
    "section": "",
    "text": "Datasets\nClean, high-quality data can be hard to come by, so I’ve gathered some datasets I personally scraped and processed. If you find any of them useful, feel free to reach out! \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEU Press Materials on Digital Policy\n\n\nA clean corpus of over 4000 documents scraped from the EU website\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLegal Texts for Competition Impact Assessment\n\n\nA labeled dataset of more than 4000 paragraphs mapped to different categories of potentially anticompetitive provisions\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "datasets.html#education",
    "href": "datasets.html#education",
    "title": "Janine De Vera",
    "section": "",
    "text": "MSc Data Science for Public Policy  Hertie School, 2021-2023  Berlin, Germany \nBS Business Economics  University of the Philippines Diliman, 2010-2014  Manila, Philippines"
  },
  {
    "objectID": "datasets.html#experience",
    "href": "datasets.html#experience",
    "title": "Janine De Vera",
    "section": "Experience",
    "text": "Experience"
  },
  {
    "objectID": "datasets/01 dsa/index.html",
    "href": "datasets/01 dsa/index.html",
    "title": "EU Press Materials on Digital Policy",
    "section": "",
    "text": "EU Digital Speeches Dataset (39 MB) 4078 rows Download here\n\n\n\n\n\n\n\n\n\n\n    \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n   \n    \n      \n  \n        \n    \n    \n  \n        \n    \n    \n  \n        \n    \n      \n  \n        \n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n        \n    \n\n\n\n\nThis is the init_notebook_mode cell from ITables v2.1.3\n(you should not see this message - is your notebook trusted?)\n\n\n\n\n\n\n\n\n    \n      \n      document\n      title\n      date\n      text\n      link\n    \n  \n\n\n\n    \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n   \n    \n      \n  \n        \n    \n    \n  \n        \n    \n    \n  \n        \n    \n      \n  \n        \n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n        \n    \n\n\n\n\nLoading ITables v2.1.3 from the init_notebook_mode cell...\n(need help?)\n\n\n\n\n\n\n\n\nAbout this dataset\nDigital platforms such as Google, Amazon, and Facebook play a crucial role in today’s technology-driven era. The increasing presence and necessity of digital innovation in our daily lives has prompted governments worldwide to actively regulate platform activities in an effort to prevent and address perceived risks and harms.\nThe European Union is a global leader in this regulatory effort, enacting landmark legislation like the Digital Services Act (DSA) and the Digital Markets Act (DMA). Among other things, these regulations aim to safeguard consumer welfare, address issues concerning data privacy and misinformation, and promote healthy market competition. The European Commission communicates these initiatives to various stakeholders through comprehensive documentation available on the EU Press Corner. The archive comprises a wide variety of press materials like speeches, statements, news articles, and factsheets on the digital policy discourse.\nThe information contained in these documents can be used to explore and answer different policy questions. For example, determining the focus of the EU’s digital strategy through topic modeling, understanding how digital policy issues are communicated through sentiment analysis, or identifying key players and stakeholders through named entity recognition.\nWith the goal of using communication materials to analyze EU digital policy, I scraped the EU Press Corner website to construct a dataset of speeches that contain the keyword digital.\nThe whole process is rather straightforward. Applying keyword and document type filters to the archive yields paginated results of all press materials that satisfy the given criteria. I parse the URLs to obtain the main text and other metadata - document type, title, date published, and link to the document. I apply some quality checks (e.g. removing duplicates and empty articles) and save the result as csv and json files, which can later be imported as a dataframe.\nA part of this process can be seen in the code below. The full source code for the scraper can be found in this  repository.\n\n\nShow code\ndef extract_text(links):\n    '''Function for extracting information from each search result.'''\n\n    print(f\"Number of links: {len(links)}\")\n\n    with tqdm(total=len(links), desc=\"Extracting text\") as pbar:\n        with open('raw.csv', 'a', newline='', encoding='utf-8') as csvfile:\n            fieldnames = [\"document\", \"title\", \"date\", \"location\", \"text\", \"link\"]\n            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n\n            for link in links:\n                soup = load_page(link)\n                title_elem = doc_elems = paragraph_elem = None\n\n                try:\n                    title_elem = soup.find(class_=\"ecl-heading ecl-heading--h1 ecl-u-color-white\")\n                    doc_elems = soup.find_all(class_=\"ecl-meta__item\")\n                    paragraph_elem = soup.find(class_=\"ecl-paragraph\")\n\n                except Exception as e:\n                    print(f\"Error on link {link}: {e}\")\n\n                title = title_elem.text if title_elem else np.nan\n                paragraph = paragraph_elem.text if paragraph_elem else np.nan\n\n                if doc_elems:\n                    doc, date, loc = (elem.text if elem else np.nan for elem in doc_elems[:3])\n                else:\n                    doc, date, loc = np.nan, np.nan, np.nan\n\n                writer.writerow({\n                    \"document\": doc,\n                    \"title\": title,\n                    \"date\": date,\n                    \"location\": loc,\n                    \"text\": paragraph,\n                    \"link\": str(link)\n                })\n\n\n\nNote: A smaller corpus of press materials (including statements, news articles, and fact sheets) specific to the Digital Services Act and Digital Markets Act is also available upon request."
  },
  {
    "objectID": "datasets/02 thesis/index.html",
    "href": "datasets/02 thesis/index.html",
    "title": "Legal Texts for Competition Impact Assessment",
    "section": "",
    "text": "Legal Texts for CIA Dataset (9 MB) 4153 rows Download here\nThis is the init_notebook_mode cell from ITables v2.1.3\n(you should not see this message - is your notebook trusted?)\n\n\n\n\n\n\n\n\n    \n      \n      Law\n      Text\n      Category\n      Category_New\n      text_clean\n    \n  \n\n\n\n    \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n   \n    \n      \n  \n        \n    \n    \n  \n        \n    \n    \n  \n        \n    \n      \n  \n        \n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n        \n    \n\n\n\n\nLoading ITables v2.1.3 from the init_notebook_mode cell...\n(need help?)"
  },
  {
    "objectID": "website/lib/python3.10/site-packages/pyzmq-26.0.3.dist-info/licenses/LICENSE.html",
    "href": "website/lib/python3.10/site-packages/pyzmq-26.0.3.dist-info/licenses/LICENSE.html",
    "title": "Janine De Vera",
    "section": "",
    "text": "BSD 3-Clause License\nCopyright (c) 2009-2012, Brian Granger, Min Ragan-Kelley\nAll rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
  },
  {
    "objectID": "datasets/02 thesis/index.html#footnotes",
    "href": "datasets/02 thesis/index.html#footnotes",
    "title": "Legal Texts for Competition Impact Assessment",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe countries included are Brazil, Brunei, Indonesia, Malaysia, Mexico, Philippines, Singapore↩︎\nThe initial distribution of labels is category A: 48%, B: 11%, C: 2%, Others: 3%, None: 36%↩︎\nBack translation is only applied to the training set (excludes the test set to avoid data leakage)↩︎"
  },
  {
    "objectID": "posts/01 thesis/index.html",
    "href": "posts/01 thesis/index.html",
    "title": "Using AI to Detect Anti-Competitive Legislation",
    "section": "",
    "text": "Competition is at the heart of consumer welfare. This is why in many countries, competition bodies assess new and existing policies for anti-competitive provisions. Competition Impact Assessment (CIA) studies are necessary for ensuring that regulations strike a balance between meeting sector-specific objectives and preserving a competitive market environment.\nIdeally, most laws should be subjected to CIA and other types of regulatory assessments. But this is a time-consuming exercise: an initial review alone can take 2-4 months, according to an OECD1 representative I spoke to. With hundreds of new laws and regulations proposed in any given country each year, the need for an efficient approach to competition impact assessment is great. Having myself worked in the Philippine Competition Commission for nearly 4 years, I have first-hand experience of how such undertakings can severely strain resources.\nRecent years have shown that machine learning and AI, particularly large language models (LLM), can greatly aid in processing massive amounts of textual data. Legal texts are no exception, and this is precisely what I demonstrated in my master’s thesis. I developed a pre-screening tool that (1) identifies legislation containing potentially anti-competitive provisions, and (2) categorizes these provisions into different types of restrictions that need to be flagged to CIA proponents.\nAI is no replacement for an expert’s thorough assessment, and when enacting policies with wide-ranging ramifications, human judgment must remain the final arbiter. But automation can be useful as a means of initial assessment, with only those having problematic provisions meriting further review. Workloads would be significantly reduced. The machine learning models I trained were able to correctly classify up to 98% of text with restrictive provisions and accurately assign up to 77% of provisions to their respective categories."
  },
  {
    "objectID": "posts/01 thesis/index.html#footnotes",
    "href": "posts/01 thesis/index.html#footnotes",
    "title": "Using AI to Detect Anti-Competitive Legislation",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nOrganisation for Economic Co-operation and Development↩︎\nIn particular, a TF-IDF (term frequency inverse document frequency) matrix. Unigrams are single words, while n-grams are phrases that are 2 to 5 words in length.↩︎\nGloVe embeddings can be downloaded here  and Legal Word2Vec can be downloaded here.↩︎\nMore than 4,200 binary model specifications were trained and tested using different hyperparameter combinations. The best models were selected through a grid search algorithm.↩︎\nGiven by the formula \\(TP / (TP + FN)\\)↩︎\nIn multi-class problems, labels are mutually exclusive so only one label is assigned per text. In reality, there could be more than one label per document (a multi-label problem). But for demonstration purposes, I choose to the simpler multi-class specification.↩︎\nSoftmax and multi-class support vector machines↩︎\n\\(TP / (TP + FP)\\)↩︎\n\\(TP / (TP + FN)\\)↩︎\nSuch as Shaheen, Wohlgenannt, and Filtz (2020) and  Gao, et. al. (2020).↩︎"
  },
  {
    "objectID": "posts/legal-text-classification/index.html",
    "href": "posts/legal-text-classification/index.html",
    "title": "Using AI to Detect Anti-Competitive Legislation",
    "section": "",
    "text": "Competition is at the heart of consumer welfare. This is why in many countries, competition bodies assess new and existing policies for anti-competitive provisions. Competition Impact Assessment (CIA) studies are necessary for ensuring that regulations strike a balance between meeting sector-specific objectives and preserving a competitive market environment.\nIdeally, most laws should be subjected to CIA and other types of regulatory assessments. But this is a time-consuming exercise: an initial review alone can take 2-4 months, according to an OECD1 representative I spoke to. With hundreds of new laws and regulations proposed in any given country each year, the need for an efficient approach to competition impact assessment is great. Having myself worked in the Philippine Competition Commission for nearly 4 years, I have first-hand experience of how such undertakings can severely strain resources.\nRecent years have shown that machine learning and AI, particularly large language models (LLM), can greatly aid in processing massive amounts of textual data. Legal texts are no exception, and this is precisely what I demonstrated in my master’s thesis. I developed a pre-screening tool that (1) identifies legislation containing potentially anti-competitive provisions, and (2) categorizes these provisions into different types of restrictions that need to be flagged to CIA proponents.\nAI is no replacement for an expert’s thorough assessment, and when enacting policies with wide-ranging ramifications, human judgment must remain the final arbiter. But automation can be useful as a means of initial assessment, with only those having problematic provisions meriting further review. Workloads would be significantly reduced. The machine learning models I trained were able to correctly classify up to 98% of text with restrictive provisions and accurately assign up to 77% of provisions to their respective categories."
  },
  {
    "objectID": "posts/legal-text-classification/index.html#footnotes",
    "href": "posts/legal-text-classification/index.html#footnotes",
    "title": "Using AI to Detect Anti-Competitive Legislation",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nOrganisation for Economic Co-operation and Development↩︎\nIn particular, a TF-IDF (term frequency inverse document frequency) matrix. Unigrams are single words, while n-grams are phrases that are 2 to 5 words in length.↩︎\nGloVe embeddings can be downloaded here  and Legal Word2Vec can be downloaded here.↩︎\nMore than 4,200 binary model specifications were trained and tested using different hyperparameter combinations. The best models were selected through a grid search algorithm.↩︎\nGiven by the formula \\(TP / (TP + FN)\\)↩︎\nIn multi-class problems, labels are mutually exclusive so only one label is assigned per text. In reality, there could be more than one label per document (a multi-label problem). But for demonstration purposes, I choose to the simpler multi-class specification.↩︎\nSoftmax and multi-class support vector machines↩︎\n\\(TP / (TP + FP)\\)↩︎\n\\(TP / (TP + FN)\\)↩︎\nSuch as Shaheen, Wohlgenannt, and Filtz (2020) and  Gao, et. al. (2020).↩︎"
  },
  {
    "objectID": "datasets/digital-policy-communications/index.html",
    "href": "datasets/digital-policy-communications/index.html",
    "title": "EU Press Materials on Digital Policy",
    "section": "",
    "text": "EU Digital Speeches Dataset (39 MB) 4078 rows Download here\n\n\n\n\n\n\n\n\n\n\n    \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n   \n    \n      \n  \n        \n    \n    \n  \n        \n    \n    \n  \n        \n    \n      \n  \n        \n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n        \n    \n\n\n\n\nThis is the init_notebook_mode cell from ITables v2.1.3\n(you should not see this message - is your notebook trusted?)\n\n\n\n\n\n\n\n\n    \n      \n      document\n      title\n      date\n      text\n      link\n    \n  \n\n\n\n    \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n   \n    \n      \n  \n        \n    \n    \n  \n        \n    \n    \n  \n        \n    \n      \n  \n        \n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n        \n    \n\n\n\n\nLoading ITables v2.1.3 from the init_notebook_mode cell...\n(need help?)\n\n\n\n\n\n\n\n\nAbout this dataset\nDigital platforms such as Google, Amazon, and Facebook play a crucial role in today’s technology-driven era. The increasing presence and necessity of digital innovation in our daily lives has prompted governments worldwide to actively regulate platform activities in an effort to prevent and address perceived risks and harms.\nThe European Union is a global leader in this regulatory effort, enacting landmark legislation like the Digital Services Act (DSA) and the Digital Markets Act (DMA). Among other things, these regulations aim to safeguard consumer welfare, address issues concerning data privacy and misinformation, and promote healthy market competition. The European Commission communicates these initiatives to various stakeholders through comprehensive documentation available on the EU Press Corner. The archive comprises a wide variety of press materials like speeches, statements, news articles, and factsheets on the digital policy discourse.\nThe information contained in these documents can be used to explore and answer different policy questions. For example, determining the focus of the EU’s digital strategy through topic modeling, understanding how digital policy issues are communicated through sentiment analysis, or identifying key players and stakeholders through named entity recognition.\nWith the goal of using communication materials to analyze EU digital policy, I scraped the EU Press Corner website to construct a dataset of speeches that contain the keyword digital.\nThe whole process is rather straightforward. Applying keyword and document type filters to the archive yields paginated results of all press materials that satisfy the given criteria. I parse the URLs to obtain the main text and other metadata - document type, title, date published, and link to the document. I apply some quality checks (e.g. removing duplicates and empty articles) and save the result as csv and json files, which can later be imported as a dataframe.\nA part of this process can be seen in the code below. The full source code for the scraper can be found in this  repository.\n\n\nShow code\ndef extract_text(links):\n    '''Function for extracting information from each search result.'''\n\n    print(f\"Number of links: {len(links)}\")\n\n    with tqdm(total=len(links), desc=\"Extracting text\") as pbar:\n        with open('raw.csv', 'a', newline='', encoding='utf-8') as csvfile:\n            fieldnames = [\"document\", \"title\", \"date\", \"location\", \"text\", \"link\"]\n            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n\n            for link in links:\n                soup = load_page(link)\n                title_elem = doc_elems = paragraph_elem = None\n\n                try:\n                    title_elem = soup.find(class_=\"ecl-heading ecl-heading--h1 ecl-u-color-white\")\n                    doc_elems = soup.find_all(class_=\"ecl-meta__item\")\n                    paragraph_elem = soup.find(class_=\"ecl-paragraph\")\n\n                except Exception as e:\n                    print(f\"Error on link {link}: {e}\")\n\n                title = title_elem.text if title_elem else np.nan\n                paragraph = paragraph_elem.text if paragraph_elem else np.nan\n\n                if doc_elems:\n                    doc, date, loc = (elem.text if elem else np.nan for elem in doc_elems[:3])\n                else:\n                    doc, date, loc = np.nan, np.nan, np.nan\n\n                writer.writerow({\n                    \"document\": doc,\n                    \"title\": title,\n                    \"date\": date,\n                    \"location\": loc,\n                    \"text\": paragraph,\n                    \"link\": str(link)\n                })\n\n\n\nNote: A smaller corpus of press materials (including statements, news articles, and fact sheets) specific to the Digital Services Act and Digital Markets Act is also available upon request."
  },
  {
    "objectID": "datasets/labeled-legal-texts/index.html",
    "href": "datasets/labeled-legal-texts/index.html",
    "title": "Legal Texts for Competition Impact Assessment",
    "section": "",
    "text": "Legal Texts for CIA Dataset (9 MB) 4153 rows Download here\nThis is the init_notebook_mode cell from ITables v2.1.3\n(you should not see this message - is your notebook trusted?)\n\n\n\n\n\n\n\n\n    \n      \n      Law\n      Text\n      Category\n      Category_New\n      text_clean\n    \n  \n\n\n\n    \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n   \n    \n      \n  \n        \n    \n    \n  \n        \n    \n    \n  \n        \n    \n      \n  \n        \n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n        \n    \n\n\n\n\nLoading ITables v2.1.3 from the init_notebook_mode cell...\n(need help?)"
  },
  {
    "objectID": "datasets/labeled-legal-texts/index.html#footnotes",
    "href": "datasets/labeled-legal-texts/index.html#footnotes",
    "title": "Legal Texts for Competition Impact Assessment",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe countries included are Brazil, Brunei, Indonesia, Malaysia, Mexico, Philippines, Singapore↩︎\nThe initial distribution of labels is category A: 48%, B: 11%, C: 2%, Others: 3%, None: 36%↩︎\nBack translation is only applied to the training set (excludes the test set to avoid data leakage)↩︎"
  },
  {
    "objectID": "portfolio/legal-text-classification/index.html",
    "href": "portfolio/legal-text-classification/index.html",
    "title": "Using AI to Detect Anti-Competitive Legislation",
    "section": "",
    "text": "Competition is at the heart of consumer welfare. This is why in many countries, competition bodies assess new and existing policies for anti-competitive provisions. Competition Impact Assessment (CIA) studies are necessary for ensuring that regulations strike a balance between meeting sector-specific objectives and preserving a competitive market environment.\nIdeally, most laws should be subjected to CIA and other types of regulatory assessments. But this is a time-consuming exercise: an initial review alone can take 2-4 months, according to an OECD1 representative I spoke to. With hundreds of new laws and regulations proposed in any given country each year, the need for an efficient approach to competition impact assessment is great. Having myself worked in the Philippine Competition Commission for nearly 4 years, I have first-hand experience of how such undertakings can severely strain resources.\nRecent years have shown that machine learning and AI, particularly large language models (LLM), can greatly aid in processing massive amounts of textual data. Legal texts are no exception, and this is precisely what I demonstrated in my master’s thesis. I developed a pre-screening tool that (1) identifies legislation containing potentially anti-competitive provisions, and (2) categorizes these provisions into different types of restrictions that need to be flagged to CIA proponents.\nAI is no replacement for an expert’s thorough assessment, and when enacting policies with wide-ranging ramifications, human judgment must remain the final arbiter. But automation can be useful as a means of initial assessment, with only those having problematic provisions meriting further review. Workloads would be significantly reduced. The machine learning models I trained were able to correctly classify up to 98% of text with restrictive provisions and accurately assign up to 77% of provisions to their respective categories."
  },
  {
    "objectID": "portfolio/legal-text-classification/index.html#footnotes",
    "href": "portfolio/legal-text-classification/index.html#footnotes",
    "title": "Using AI to Detect Anti-Competitive Legislation",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nOrganisation for Economic Co-operation and Development↩︎\nIn particular, a TF-IDF (term frequency inverse document frequency) matrix. Unigrams are single words, while n-grams are phrases that are 2 to 5 words in length.↩︎\nGloVe embeddings can be downloaded here  and Legal Word2Vec can be downloaded here.↩︎\nMore than 4,200 binary model specifications were trained and tested using different hyperparameter combinations. The best models were selected through a grid search algorithm.↩︎\nGiven by the formula \\(TP / (TP + FN)\\)↩︎\nIn multi-class problems, labels are mutually exclusive so only one label is assigned per text. In reality, there could be more than one label per document (a multi-label problem). But for demonstration purposes, I choose to the simpler multi-class specification.↩︎\nSoftmax and multi-class support vector machines↩︎\n\\(TP / (TP + FP)\\)↩︎\n\\(TP / (TP + FN)\\)↩︎\nSuch as Shaheen, Wohlgenannt, and Filtz (2020) and  Gao, et. al. (2020).↩︎"
  },
  {
    "objectID": "portfolio/trade-networks/index.html",
    "href": "portfolio/trade-networks/index.html",
    "title": "Friendly Countries Make Deep Trade Agreements",
    "section": "",
    "text": "Network science aims to understand systems that are “hopelessly complicated” 1, from brain neurons to words in a language. One such system is the formation of trade agreements between countries. Indeed, since the relationship between two countries is often also influenced by their relationship with others, network analysis is a potent tool for uncovering new insights on top of the traditional regression-based gravity model.\nIn this study, I explored the dynamics of a particular set of free trade agreements – deep FTAs – and found that their creation is actually quite similar to how we make social connections. The social network concepts of transitivity and homophily are both observed in deep FTA networks. The phrases “a friend of a friend is a friend” and “birds of a feather flock together” also apply to how countries choose trade partners. In particular, similarities in political institutions attract countries to potentially deep FTA partners."
  },
  {
    "objectID": "portfolio/trade-networks/index.html#footnotes",
    "href": "portfolio/trade-networks/index.html#footnotes",
    "title": "Friendly Countries Make Deep Trade Agreements",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nAlbert-László Barabási in Network Science.↩︎\nThe main text, including the title and signature pages, is 8,186 words long. The document can be accessed here.↩︎\nThe main text, including the title and signature pages, is 47,505 words long. The document can be accessed here.↩︎\nNon-economic policies are defined in Limão (2016).↩︎\nIf a country belongs to a multiparty agreement (e.g. ASEAN), each bilateral partnership (e.g. Singapore–Philippines, Singapore–Malaysia, Singapore–Thailand) is counted as one connection.↩︎\nThe application of this method to trade agreements was first explored in Lee and Bai (2013).↩︎\nThe ERG model coefficients are log-odds ratios which can be converted to probabilities using the inverse logit function \\(exp(x)/(1+exp(x))\\). The log-odds ratio for transitivity is 0.694.↩︎\nIn the full network, a country pair being both democracies only makes it 60% more likely for a FTA to form.↩︎\nA trade agreement between two countries in the same region is 92% more likely than between countries from different region. In the deep trade network, belonging to the same region only makes in 82% more likely for a FTA to form.↩︎"
  },
  {
    "objectID": "website/lib/python3.10/site-packages/toolz-0.12.1.dist-info/AUTHORS.html",
    "href": "website/lib/python3.10/site-packages/toolz-0.12.1.dist-info/AUTHORS.html",
    "title": "Janine De Vera",
    "section": "",
    "text": "Matthew Rocklin @mrocklin\nJohn Jacobsen @eigenhombre\nErik Welch @eriknw\nJohn Crichton @jcrichton\nHan Semaj @microamp\nGraeme Coupar @obmarg\nLeonid Shvechikov @shvechikov\nLars Buitinck @larsmans\nJosé Ricardo @josericardo\nTom Prince @tomprince\nBart van Merriënboer @bartvm\nNikolaos-Digenis Karagiannis @digenis\nAntonio Lima @themiurgo\nJoe Jevnik @llllllllll\nRory Kirchner @roryk\nSteven Cutting @steven_cutting\nAric Coady @coady"
  },
  {
    "objectID": "website/lib/python3.10/site-packages/nltk-3.8.1.dist-info/AUTHORS.html",
    "href": "website/lib/python3.10/site-packages/nltk-3.8.1.dist-info/AUTHORS.html",
    "title": "Natural Language Toolkit (NLTK) Authors",
    "section": "",
    "text": "Steven Bird stevenbird1@gmail.com\nEdward Loper edloper@gmail.com\nEwan Klein ewan@inf.ed.ac.uk\n\n\n\n\n\nTom Aarsen\nRami Al-Rfou’\nMark Amery\nGreg Aumann\nIvan Barria\nIngolf Becker\nYonatan Becker\nPaul Bedaride\nSteven Bethard\nRobert Berwick\nDan Blanchard\nNathan Bodenstab\nAlexander Böhm\nFrancis Bond\nPaul Bone\nJordan Boyd-Graber\nDaniel Blanchard\nPhil Blunsom\nLars Buitinck\nCristian Capdevila\nSteve Cassidy\nChen-Fu Chiang\nDmitry Chichkov\nJinyoung Choi\nAndrew Clausen\nLucas Champollion\nGraham Christensen\nTrevor Cohn\nDavid Coles\nTom Conroy https://github.com/tconroy\nClaude Coulombe\nLucas Cooper\nRobin Cooper\nChris Crowner\nJames Curran\nArthur Darcet\nDariel Dato-on\nSelina Dennis\nLeon Derczynski\nAlexis Dimitriadis\nNikhil Dinesh\nLiang Dong\nDavid Doukhan\nRebecca Dridan\nPablo Duboue\nLong Duong\nChristian Federmann\nCampion Fellin\nMichelle Fullwood\nDan Garrette\nMaciej Gawinecki\nJean Mark Gawron\nSumukh Ghodke\nYoav Goldberg\nMichael Wayne Goodman\nDougal Graham\nBrent Gray\nSimon Greenhill\nClark Grubb\nEduardo Pereira Habkost\nMasato Hagiwara\nLauri Hallila\nMichael Hansen\nYurie Hara\nWill Hardy\nTyler Hartley\nPeter Hawkins\nSaimadhav Heblikar\nFredrik Hedman\nHelder\nMichael Heilman\nOfer Helman\nChristopher Hench\nBruce Hill\nAmy Holland\nKristy Hollingshead\nMarcus Huderle\nBaden Hughes\nNancy Ide\nRebecca Ingram\nEdward Ivanovic\nThomas Jakobsen\nNick Johnson\nEric Kafe\nPiotr Kasprzyk\nAngelos Katharopoulos\nSudharshan Kaushik\nChris Koenig\nMikhail Korobov\nDenis Krusko\nIlia Kurenkov\nStefano Lattarini\nPierre-François Laquerre\nStefano Lattarini\nHaejoong Lee\nJackson Lee\nMax Leonov\nChris Liechti\nHyuckin David Lim\nTom Lippincott\nPeter Ljunglöf\nAlex Louden\nJoseph Lynch\nNitin Madnani\nFelipe Madrigal\nBjørn Mæland\nDean Malmgren\nChristopher Maloof\nRob Malouf\nIker Manterola\nCarl de Marcken\nMitch Marcus\nTorsten Marek\nRobert Marshall\nMarius Mather\nDuncan McGreggor\nDavid McClosky\nXinfan Meng\nDmitrijs Milajevs\nMargaret Mitchell\nTomonori Nagano\nJason Narad\nShari A’aidil Nasruddin\nLance Nathan\nMorten Neergaard\nDavid Nemeskey\nEric Nichols\nJoel Nothman\nAlireza Nourian\nAlexander Oleynikov\nPierpaolo Pantone\nTed Pedersen\nJacob Perkins\nAlberto Planas\nOndrej Platek\nAlessandro Presta\nQi Liu\nMartin Thorsen Ranang\nMichael Recachinas\nBrandon Rhodes\nJoshua Ritterman\nWill Roberts\nStuart Robinson\nCarlos Rodriguez\nLorenzo Rubio\nAlex Rudnick\nJussi Salmela\nGeoffrey Sampson\nKepa Sarasola\nKevin Scannell\nNathan Schneider\nRico Sennrich\nThomas Skardal\nEric Smith\nLynn Soe\nRob Speer\nPeter Spiller\nRichard Sproat\nCeri Stagg\nPeter Stahl\nOliver Steele\nThomas Stieglmaier\nJan Strunk\nLiling Tan\nClaire Taylor\nLouis Tiao\nSteven Tomcavage\nTiago Tresoldi\nMarcus Uneson\nYu Usami\nPetro Verkhogliad\nPeter Wang\nZhe Wang\nCharlotte Wilson\nChuck Wooters\nSteven Xu\nBeracah Yankama\nLei Ye (叶磊)\nPatrick Ye\nGeraldine Sim Wei Ying\nJason Yoder\nThomas Zieglier\n0ssifrage\nducki13\nkiwipi\nlade\nisnowfy\nonesandzeros\npquentin\nwvanlint\nÁlvaro Justen https://github.com/turicas\nbjut-hz\nSergio Oller\nWill Monroe\nElijah Rippeth\nEmil Manukyan\nCasper Lehmann-Strøm\nAndrew Giel\nTanin Na Nakorn\nLinghao Zhang\nColin Carroll\nHeguang Miao\nHannah Aizenman (story645)\nGeorge Berry\nAdam Nelson\nJ Richard Snape\nAlex Constantin alex@keyworder.ch\nTsolak Ghukasyan\nPrasasto Adi\nSafwan Kamarrudin\nArthur Tilley\nVilhjalmur Thorsteinsson\nJaehoon Hwang https://github.com/jaehoonhwang\nChintan Shah https://github.com/chintanshah24\nsbagan\nZicheng Xu\nAlbert Au Yeung https://github.com/albertauyeung\nShenjian Zhao\nDeng Wang https://github.com/lmatt-bit\nAli Abdullah\nStoytcho Stoytchev\nLakhdar Benzahia\nKheireddine Abainia https://github.com/xprogramer\nYibin Lin https://github.com/yibinlin\nArtiem Krinitsyn\nBjörn Mattsson\nOleg Chislov\nPavan Gururaj Joshi https://github.com/PavanGJ\nEthan Hill https://github.com/hill1303\nVivek Lakshmanan\nSomnath Rakshit https://github.com/somnathrakshit\nAnlan Du\nPulkit Maloo https://github.com/pulkitmaloo\nBrandon M. Burroughs https://github.com/brandonmburroughs\nJohn Stewart https://github.com/free-variation\nIaroslav Tymchenko https://github.com/myproblemchild\nAleš Tamchyna\nTim Gianitsos https://github.com/timgianitsos\nPhilippe Partarrieu https://github.com/ppartarr\nAndrew Owen Martin\nAdrian Ellis https://github.com/adrianjellis\nNat Quayle Nelson https://github.com/nqnstudios\nYanpeng Zhao https://github.com/zhaoyanpeng\nMatan Rak https://github.com/matanrak\nNick Ulle https://github.com/nick-ulle\nUday Krishna https://github.com/udaykrishna\nOsman Zubair https://github.com/okz12\nViresh Gupta https://github.com/virresh\nOndřej Cífka https://github.com/cifkao\nIris X. Zhou https://github.com/irisxzhou\nDevashish Lal https://github.com/BLaZeKiLL\nGerhard Kremer https://github.com/GerhardKa\nNicolas Darr https://github.com/ndarr\nHervé Nicol https://github.com/hervenicol\nAlexandre H. T. Dias https://github.com/alexandredias3d\nDaksh Shah https://github.com/Daksh\nJacob Weightman https://github.com/jacobdweightman\nBonifacio de Oliveira https://github.com/Bonifacio2\nArmins Bagrats Stepanjans https://github.com/ab-10\nVassilis Palassopoulos https://github.com/palasso\nRam Rachum https://github.com/cool-RR\nOr Sharir https://github.com/orsharir\nDenali Molitor https://github.com/dmmolitor\nJacob Moorman https://github.com/jdmoorman\nCory Nezin https://github.com/corynezin\nMatt Chaput\nDanny Sepler https://github.com/dannysepler\nAkshita Bhagia https://github.com/AkshitaB\nPratap Yadav https://github.com/prtpydv\nHiroki Teranishi https://github.com/chantera\nRuben Cartuyvels https://github.com/rubencart\nDalton Pearson https://github.com/daltonpearson\nRobby Horvath https://github.com/robbyhorvath\nGavish Poddar https://github.com/gavishpoddar\nSaibo Geng https://github.com/Saibo-creator\nAhmet Yildirim https://github.com/RnDevelover\nYuta Nakamura https://github.com/yutanakamura-tky\nAdam Hawley https://github.com/adamjhawley\nPanagiotis Simakis https://github.com/sp1thas\nRichard Wang https://github.com/richarddwang\nAlexandre Perez-Lebel https://github.com/aperezlebel\nFernando Carranza https://github.com/fernandocar86\nMartin Kondratzky https://github.com/martinkondra\nHeungson Lee https://github.com/heungson\nM.K. Pawelkiewicz https://github.com/hamiltonianflow\nSteven Thomas Smith https://github.com/essandess\nJan Lennartz https://github.com/Madnex\n\n\n\n\n\n\n\nMartin Porter\nVivake Gupta\nBarry Wilkins\nHiranmay Ghosh\nChris Emerson\n\n\n\n\n\nAssem Chelli\nAbdelkrim Aries\nLakhdar Benzahia"
  },
  {
    "objectID": "website/lib/python3.10/site-packages/nltk-3.8.1.dist-info/AUTHORS.html#original-authors",
    "href": "website/lib/python3.10/site-packages/nltk-3.8.1.dist-info/AUTHORS.html#original-authors",
    "title": "Natural Language Toolkit (NLTK) Authors",
    "section": "",
    "text": "Steven Bird stevenbird1@gmail.com\nEdward Loper edloper@gmail.com\nEwan Klein ewan@inf.ed.ac.uk"
  },
  {
    "objectID": "website/lib/python3.10/site-packages/nltk-3.8.1.dist-info/AUTHORS.html#contributors",
    "href": "website/lib/python3.10/site-packages/nltk-3.8.1.dist-info/AUTHORS.html#contributors",
    "title": "Natural Language Toolkit (NLTK) Authors",
    "section": "",
    "text": "Tom Aarsen\nRami Al-Rfou’\nMark Amery\nGreg Aumann\nIvan Barria\nIngolf Becker\nYonatan Becker\nPaul Bedaride\nSteven Bethard\nRobert Berwick\nDan Blanchard\nNathan Bodenstab\nAlexander Böhm\nFrancis Bond\nPaul Bone\nJordan Boyd-Graber\nDaniel Blanchard\nPhil Blunsom\nLars Buitinck\nCristian Capdevila\nSteve Cassidy\nChen-Fu Chiang\nDmitry Chichkov\nJinyoung Choi\nAndrew Clausen\nLucas Champollion\nGraham Christensen\nTrevor Cohn\nDavid Coles\nTom Conroy https://github.com/tconroy\nClaude Coulombe\nLucas Cooper\nRobin Cooper\nChris Crowner\nJames Curran\nArthur Darcet\nDariel Dato-on\nSelina Dennis\nLeon Derczynski\nAlexis Dimitriadis\nNikhil Dinesh\nLiang Dong\nDavid Doukhan\nRebecca Dridan\nPablo Duboue\nLong Duong\nChristian Federmann\nCampion Fellin\nMichelle Fullwood\nDan Garrette\nMaciej Gawinecki\nJean Mark Gawron\nSumukh Ghodke\nYoav Goldberg\nMichael Wayne Goodman\nDougal Graham\nBrent Gray\nSimon Greenhill\nClark Grubb\nEduardo Pereira Habkost\nMasato Hagiwara\nLauri Hallila\nMichael Hansen\nYurie Hara\nWill Hardy\nTyler Hartley\nPeter Hawkins\nSaimadhav Heblikar\nFredrik Hedman\nHelder\nMichael Heilman\nOfer Helman\nChristopher Hench\nBruce Hill\nAmy Holland\nKristy Hollingshead\nMarcus Huderle\nBaden Hughes\nNancy Ide\nRebecca Ingram\nEdward Ivanovic\nThomas Jakobsen\nNick Johnson\nEric Kafe\nPiotr Kasprzyk\nAngelos Katharopoulos\nSudharshan Kaushik\nChris Koenig\nMikhail Korobov\nDenis Krusko\nIlia Kurenkov\nStefano Lattarini\nPierre-François Laquerre\nStefano Lattarini\nHaejoong Lee\nJackson Lee\nMax Leonov\nChris Liechti\nHyuckin David Lim\nTom Lippincott\nPeter Ljunglöf\nAlex Louden\nJoseph Lynch\nNitin Madnani\nFelipe Madrigal\nBjørn Mæland\nDean Malmgren\nChristopher Maloof\nRob Malouf\nIker Manterola\nCarl de Marcken\nMitch Marcus\nTorsten Marek\nRobert Marshall\nMarius Mather\nDuncan McGreggor\nDavid McClosky\nXinfan Meng\nDmitrijs Milajevs\nMargaret Mitchell\nTomonori Nagano\nJason Narad\nShari A’aidil Nasruddin\nLance Nathan\nMorten Neergaard\nDavid Nemeskey\nEric Nichols\nJoel Nothman\nAlireza Nourian\nAlexander Oleynikov\nPierpaolo Pantone\nTed Pedersen\nJacob Perkins\nAlberto Planas\nOndrej Platek\nAlessandro Presta\nQi Liu\nMartin Thorsen Ranang\nMichael Recachinas\nBrandon Rhodes\nJoshua Ritterman\nWill Roberts\nStuart Robinson\nCarlos Rodriguez\nLorenzo Rubio\nAlex Rudnick\nJussi Salmela\nGeoffrey Sampson\nKepa Sarasola\nKevin Scannell\nNathan Schneider\nRico Sennrich\nThomas Skardal\nEric Smith\nLynn Soe\nRob Speer\nPeter Spiller\nRichard Sproat\nCeri Stagg\nPeter Stahl\nOliver Steele\nThomas Stieglmaier\nJan Strunk\nLiling Tan\nClaire Taylor\nLouis Tiao\nSteven Tomcavage\nTiago Tresoldi\nMarcus Uneson\nYu Usami\nPetro Verkhogliad\nPeter Wang\nZhe Wang\nCharlotte Wilson\nChuck Wooters\nSteven Xu\nBeracah Yankama\nLei Ye (叶磊)\nPatrick Ye\nGeraldine Sim Wei Ying\nJason Yoder\nThomas Zieglier\n0ssifrage\nducki13\nkiwipi\nlade\nisnowfy\nonesandzeros\npquentin\nwvanlint\nÁlvaro Justen https://github.com/turicas\nbjut-hz\nSergio Oller\nWill Monroe\nElijah Rippeth\nEmil Manukyan\nCasper Lehmann-Strøm\nAndrew Giel\nTanin Na Nakorn\nLinghao Zhang\nColin Carroll\nHeguang Miao\nHannah Aizenman (story645)\nGeorge Berry\nAdam Nelson\nJ Richard Snape\nAlex Constantin alex@keyworder.ch\nTsolak Ghukasyan\nPrasasto Adi\nSafwan Kamarrudin\nArthur Tilley\nVilhjalmur Thorsteinsson\nJaehoon Hwang https://github.com/jaehoonhwang\nChintan Shah https://github.com/chintanshah24\nsbagan\nZicheng Xu\nAlbert Au Yeung https://github.com/albertauyeung\nShenjian Zhao\nDeng Wang https://github.com/lmatt-bit\nAli Abdullah\nStoytcho Stoytchev\nLakhdar Benzahia\nKheireddine Abainia https://github.com/xprogramer\nYibin Lin https://github.com/yibinlin\nArtiem Krinitsyn\nBjörn Mattsson\nOleg Chislov\nPavan Gururaj Joshi https://github.com/PavanGJ\nEthan Hill https://github.com/hill1303\nVivek Lakshmanan\nSomnath Rakshit https://github.com/somnathrakshit\nAnlan Du\nPulkit Maloo https://github.com/pulkitmaloo\nBrandon M. Burroughs https://github.com/brandonmburroughs\nJohn Stewart https://github.com/free-variation\nIaroslav Tymchenko https://github.com/myproblemchild\nAleš Tamchyna\nTim Gianitsos https://github.com/timgianitsos\nPhilippe Partarrieu https://github.com/ppartarr\nAndrew Owen Martin\nAdrian Ellis https://github.com/adrianjellis\nNat Quayle Nelson https://github.com/nqnstudios\nYanpeng Zhao https://github.com/zhaoyanpeng\nMatan Rak https://github.com/matanrak\nNick Ulle https://github.com/nick-ulle\nUday Krishna https://github.com/udaykrishna\nOsman Zubair https://github.com/okz12\nViresh Gupta https://github.com/virresh\nOndřej Cífka https://github.com/cifkao\nIris X. Zhou https://github.com/irisxzhou\nDevashish Lal https://github.com/BLaZeKiLL\nGerhard Kremer https://github.com/GerhardKa\nNicolas Darr https://github.com/ndarr\nHervé Nicol https://github.com/hervenicol\nAlexandre H. T. Dias https://github.com/alexandredias3d\nDaksh Shah https://github.com/Daksh\nJacob Weightman https://github.com/jacobdweightman\nBonifacio de Oliveira https://github.com/Bonifacio2\nArmins Bagrats Stepanjans https://github.com/ab-10\nVassilis Palassopoulos https://github.com/palasso\nRam Rachum https://github.com/cool-RR\nOr Sharir https://github.com/orsharir\nDenali Molitor https://github.com/dmmolitor\nJacob Moorman https://github.com/jdmoorman\nCory Nezin https://github.com/corynezin\nMatt Chaput\nDanny Sepler https://github.com/dannysepler\nAkshita Bhagia https://github.com/AkshitaB\nPratap Yadav https://github.com/prtpydv\nHiroki Teranishi https://github.com/chantera\nRuben Cartuyvels https://github.com/rubencart\nDalton Pearson https://github.com/daltonpearson\nRobby Horvath https://github.com/robbyhorvath\nGavish Poddar https://github.com/gavishpoddar\nSaibo Geng https://github.com/Saibo-creator\nAhmet Yildirim https://github.com/RnDevelover\nYuta Nakamura https://github.com/yutanakamura-tky\nAdam Hawley https://github.com/adamjhawley\nPanagiotis Simakis https://github.com/sp1thas\nRichard Wang https://github.com/richarddwang\nAlexandre Perez-Lebel https://github.com/aperezlebel\nFernando Carranza https://github.com/fernandocar86\nMartin Kondratzky https://github.com/martinkondra\nHeungson Lee https://github.com/heungson\nM.K. Pawelkiewicz https://github.com/hamiltonianflow\nSteven Thomas Smith https://github.com/essandess\nJan Lennartz https://github.com/Madnex"
  },
  {
    "objectID": "website/lib/python3.10/site-packages/nltk-3.8.1.dist-info/AUTHORS.html#others-whose-work-weve-taken-and-included-in-nltk-but-who-didnt-directly-contribute-it",
    "href": "website/lib/python3.10/site-packages/nltk-3.8.1.dist-info/AUTHORS.html#others-whose-work-weve-taken-and-included-in-nltk-but-who-didnt-directly-contribute-it",
    "title": "Natural Language Toolkit (NLTK) Authors",
    "section": "",
    "text": "Martin Porter\nVivake Gupta\nBarry Wilkins\nHiranmay Ghosh\nChris Emerson\n\n\n\n\n\nAssem Chelli\nAbdelkrim Aries\nLakhdar Benzahia"
  },
  {
    "objectID": "website/lib/python3.10/site-packages/matplotlib/backends/web_backend/nbagg_uat.html",
    "href": "website/lib/python3.10/site-packages/matplotlib/backends/web_backend/nbagg_uat.html",
    "title": "UAT for NbAgg backend.",
    "section": "",
    "text": "from imp import reload\nThe first line simply reloads matplotlib, uses the nbagg backend and then reloads the backend, just to ensure we have the latest modification to the backend code. Note: The underlying JavaScript will not be updated by this process, so a refresh of the browser after clearing the output and saving is necessary to clear everything fully.\nimport matplotlib\nreload(matplotlib)\n\nmatplotlib.use('nbagg')\n\nimport matplotlib.backends.backend_nbagg\nreload(matplotlib.backends.backend_nbagg)"
  },
  {
    "objectID": "website/lib/python3.10/site-packages/matplotlib/backends/web_backend/nbagg_uat.html#uat-13---animation",
    "href": "website/lib/python3.10/site-packages/matplotlib/backends/web_backend/nbagg_uat.html#uat-13---animation",
    "title": "UAT for NbAgg backend.",
    "section": "UAT 13 - Animation",
    "text": "UAT 13 - Animation\nThe following should generate an animated line:\n\nimport matplotlib.animation as animation\nimport numpy as np\n\nfig, ax = plt.subplots()\n\nx = np.arange(0, 2*np.pi, 0.01)        # x-array\nline, = ax.plot(x, np.sin(x))\n\ndef animate(i):\n    line.set_ydata(np.sin(x+i/10.0))  # update the data\n    return line,\n\n#Init only required for blitting to give a clean slate.\ndef init():\n    line.set_ydata(np.ma.array(x, mask=True))\n    return line,\n\nani = animation.FuncAnimation(fig, animate, np.arange(1, 200), init_func=init,\n                              interval=100., blit=True)\nplt.show()\n\n\nUAT 14 - Keyboard shortcuts in IPython after close of figure\nAfter closing the previous figure (with the close button above the figure) the IPython keyboard shortcuts should still function.\n\n\nUAT 15 - Figure face colours\nThe nbagg honours all colours apart from that of the figure.patch. The two plots below should produce a figure with a red background. There should be no yellow figure.\n\nimport matplotlib\nmatplotlib.rcParams.update({'figure.facecolor': 'red',\n                            'savefig.facecolor': 'yellow'})\nplt.figure()\nplt.plot([3, 2, 1])\n\nplt.show()\n\n\n\nUAT 16 - Events\nPressing any keyboard key or mouse button (or scrolling) should cycle the line line while the figure has focus. The figure should have focus by default when it is created and re-gain it by clicking on the canvas. Clicking anywhere outside of the figure should release focus, but moving the mouse out of the figure should not release focus.\n\nimport itertools\nfig, ax = plt.subplots()\nx = np.linspace(0,10,10000)\ny = np.sin(x)\nln, = ax.plot(x,y)\nevt = []\ncolors = iter(itertools.cycle(['r', 'g', 'b', 'k', 'c']))\ndef on_event(event):\n    if event.name.startswith('key'):\n        fig.suptitle('%s: %s' % (event.name, event.key))\n    elif event.name == 'scroll_event':\n        fig.suptitle('%s: %s' % (event.name, event.step))\n    else:\n        fig.suptitle('%s: %s' % (event.name, event.button))\n    evt.append(event)\n    ln.set_color(next(colors))\n    fig.canvas.draw()\n    fig.canvas.draw_idle()\n\nfig.canvas.mpl_connect('button_press_event', on_event)\nfig.canvas.mpl_connect('button_release_event', on_event)\nfig.canvas.mpl_connect('scroll_event', on_event)\nfig.canvas.mpl_connect('key_press_event', on_event)\nfig.canvas.mpl_connect('key_release_event', on_event)\n\nplt.show()\n\n\n\nUAT 17 - Timers\nSingle-shot timers follow a completely different code path in the nbagg backend than regular timers (such as those used in the animation example above.) The next set of tests ensures that both “regular” and “single-shot” timers work properly.\nThe following should show a simple clock that updates twice a second:\n\nimport time\n\nfig, ax = plt.subplots()\ntext = ax.text(0.5, 0.5, '', ha='center')\n\ndef update(text):\n    text.set(text=time.ctime())\n    text.axes.figure.canvas.draw()\n    \ntimer = fig.canvas.new_timer(500, [(update, [text], {})])\ntimer.start()\nplt.show()\n\nHowever, the following should only update once and then stop:\n\nfig, ax = plt.subplots()\ntext = ax.text(0.5, 0.5, '', ha='center') \ntimer = fig.canvas.new_timer(500, [(update, [text], {})])\n\ntimer.single_shot = True\ntimer.start()\n\nplt.show()\n\nAnd the next two examples should never show any visible text at all:\n\nfig, ax = plt.subplots()\ntext = ax.text(0.5, 0.5, '', ha='center')\ntimer = fig.canvas.new_timer(500, [(update, [text], {})])\n\ntimer.start()\ntimer.stop()\n\nplt.show()\n\n\nfig, ax = plt.subplots()\ntext = ax.text(0.5, 0.5, '', ha='center')\ntimer = fig.canvas.new_timer(500, [(update, [text], {})])\n\ntimer.single_shot = True\ntimer.start()\ntimer.stop()\n\nplt.show()\n\n\n\nUAT 18 - stopping figure when removed from DOM\nWhen the div that contains from the figure is removed from the DOM the figure should shut down it’s comm, and if the python-side figure has no more active comms, it should destroy the figure. Repeatedly running the cell below should always have the same figure number\n\nfig, ax = plt.subplots()\nax.plot(range(5))\nplt.show()\n\nRunning the cell below will re-show the figure. After this, re-running the cell above should result in a new figure number.\n\nfig.canvas.manager.reshow()\n\n\n\nUAT 19 - Blitting\nClicking on the figure should plot a green horizontal line moving up the axes.\n\nimport itertools\n\ncnt = itertools.count()\nbg = None\n\ndef onclick_handle(event):\n    \"\"\"Should draw elevating green line on each mouse click\"\"\"\n    global bg\n    if bg is None:\n        bg = ax.figure.canvas.copy_from_bbox(ax.bbox) \n    ax.figure.canvas.restore_region(bg)\n\n    cur_y = (next(cnt) % 10) * 0.1\n    ln.set_ydata([cur_y, cur_y])\n    ax.draw_artist(ln)\n    ax.figure.canvas.blit(ax.bbox)\n\nfig, ax = plt.subplots()\nax.plot([0, 1], [0, 1], 'r')\nln, = ax.plot([0, 1], [0, 0], 'g', animated=True)\nplt.show()\nax.figure.canvas.draw()\n\nax.figure.canvas.mpl_connect('button_press_event', onclick_handle)"
  },
  {
    "objectID": "portfolio/migration-sentiment-monitor/src/main/scraper_dev.html",
    "href": "portfolio/migration-sentiment-monitor/src/main/scraper_dev.html",
    "title": "Janine De Vera",
    "section": "",
    "text": "# standard libraries\nimport re\nimport datetime\nimport os\nimport time\nimport csv\nimport numpy as np\n\n# web services\nimport requests\nfrom bs4 import BeautifulSoup\nfrom selenium import webdriver\nfrom selenium.webdriver.chrome.service import Service as ChromeService \nfrom webdriver_manager.chrome import ChromeDriverManager \nfrom tqdm import tqdm\nfrom urllib.parse import urljoin\nimport undetected_chromedriver as uc\n\n\nbase_url = 'https://www.reuters.com'\nsearch_url = '/site-search/?query=migration+OR+migrant&date=any_time&offset='\nnum_pages = 100\n        \ndef parse_page(link):\n    options = webdriver.ChromeOptions()\n    options.add_argument('--headless')\n\n    driver = webdriver.Chrome(service = ChromeService(ChromeDriverManager().install()))\n    driver.get(link)\n    time.sleep(5) \n    soup = BeautifulSoup(driver.page_source, 'html.parser')\n\n    return soup\n\ndef get_result_pages(num_pages):\n    result_pages = []\n    for i in range(0, num_pages*20, 20):\n        page_link = f'{base_url}{search_url}{i}'\n        result_pages.append(page_link)\n    return result_pages\n    \ndef get_news_urls(n):\n    news_urls = []\n    result_pages = get_result_pages(n)\n\n    for result in result_pages: \n        main_soup = parse_page(result)\n        main_class = main_soup.find_all(class_='basic-card__container__1y8wi')\n\n        for item in main_class: \n            url = item.attrs['href']\n            url = f'{base_url}{url}'\n            news_urls.append(url)\n        \n    return news_urls\n            \n\n\nsoup = parse_page(f'{base_url}{search_url}{0}')\n\n\nmain = soup.find_all(class_='basic-card__container__1y8wi')\n\n\nlink = parse_page('https://www.reuters.com/world/europe/spains-far-right-threatens-exit-regional-coalitions-over-migrant-plan-2024-07-11/')\n\n\ndate = link.find(class_='date-line__date___kNbY')\ndate.text\n\n'July 11, 2024'\n\n\n\nmaintext = ' '.join([para.text for para in text])\nmaintext\n\n'MADRID, July 11 (Reuters) - Spanish far-right party Vox has threatened to bring down coalition governments with the centre-right People\\'s Party in several regions in protest over an agreement to transfer around 400 young migrants from the Canary Islands to mainland Spain. The People\\'s Party, which runs five regions including Valencia in coalition with Vox, said on Wednesday it would back a plan by Spain\\'s central Socialist-run government to move the under-18s. The government said it had focussed on 400 of the 6,000 unaccompanied young migrants from West Africa who are currently on the archipelago to ease pressure on infrastructure. It has urged Spanish regions to take in arrivals. \"Today (the People\\'s Party) has blown up (regional) government deals, welcoming voluntarily 400 underage migrants,\" Vox leader Santiago Abascal wrote on X late on Wednesday. \"Do not count on us to scam, loot and endanger Spaniards.\" Vox\\'s leadership was due to meet later on Thursday to decide whether to follow through on its threat. Without Vox, the People\\'s Party could run minority governments but would struggle to pass bills and get budgets approved. The People\\'s Party runs the Canaries with another party. It put out a statement asking why Vox would considering undermining regional bodies that governed 11 million Spaniards in the Balearic Islands and the other regions because of a small number of migrant children. \"Vox cannot say it is patriotic and leave children who are not to blame for anything stranded,\" Cuca Gamarra, the Secretary General of the People\\'s Party, said. Socialist spokesperson Patxi Lopez said it was hard to accept that there were members of regional governments \"who say that these children come with machetes and are criminals\". An increasing number of migrants arriving the Canary Islands from West Africa has put a strain on the archipelago\\'s infrastructure, Regional Policy Minister Angel Victor Torres said on Thursday. More than 16,500 migrants arrived in the first five months of 2024, five times more than the same period a year earlier, according to government figures. Vox was founded in 2013 and has become the third largest at the national level in Spain. But, while far-right parties saw a strong performance in this year\\'s European Parliament elections, Vox saw its share of the vote in Spain fall compared with the national election in July 2023. Under-18s who migrate alone to Spain are entitled to government protection and aid under Spanish law. In 2022, Spain offered more funding to regions that volunteered to host unaccompanied young migrants. But, to date, few conservative-run regions have accepted more than a handful. The central government says it is now considering making transfers compulsory once the numbers in reception centres in the Canaries reach a certain level.'\n\n\n\ndef extract_text(news_urls):\n        no_urls = len(news_urls)\n        print(f\"Number of links: {no_urls}\")\n\n        with tqdm(total=no_urls, desc=\"Extracting text\") as pbar:\n            with open('raw.csv', 'a', newline='', encoding='utf-8') as csvfile:\n                fieldnames = [\"title\", \"date\", \"text\", \"link\"]\n                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n\n                for url in news_urls:\n                    url_soup = parse_page(url)\n                    title_elem = date_elem = text_elem = None\n\n                    try:\n                        title_elem = url_soup.find('h1', attrs={'data-testid': 'Heading'})\n                        date_elem = url_soup.find(class_='date-line__date___kNbY')\n                        maintext_elem = url_soup.find_all('div', attrs={'data-testid': re.compile(r'^paragraph-\\d+$')})\n\n                    except Exception as e:\n                        print(f\"Error on link {url}: {e}\")\n\n                    title = title_elem.text if title_elem else np.nan\n                    date = date_elem.text if date_elem else np.nan\n                    maintext = ' '.join([para.text for para in maintext_elem]) if maintext_elem else np.nan\n\n                    writer.writerow({\n                        \"title\": title,\n                        \"date\": date,\n                        \"text\": maintext,\n                        \"link\": str(url)\n                    })\n\n                    pbar.update(1)\n\n\nlinks = get_news_urls(1)\n\n\ndocs = extract_text(links[1:2])\n\nNumber of links: 1\n\n\nExtracting text: 100%|██████████| 1/1 [00:09&lt;00:00,  9.20s/it]"
  },
  {
    "objectID": "portfolio/migration-sentiment-monitor/src/main/analyzer_dev.html",
    "href": "portfolio/migration-sentiment-monitor/src/main/analyzer_dev.html",
    "title": "Sentiment over time",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os \nfrom datetime import datetime\nfrom collections import Counter\n\n# text analysis\nimport ssl\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import sent_tokenize, word_tokenize\nfrom nltk.sentiment import SentimentIntensityAnalyzer\nfrom string import punctuation\nimport plotly.express as px\nimport plotly.graph_objects as go \nimport spacy \nfrom spacy import displacy\nfrom spacy.tokens import Doc\nfrom spacy.vocab import Vocab\nimport gensim\nfrom gensim.corpora import Dictionary\nfrom gensim.models import LdaModel, LdaMulticore, CoherenceModel, LsiModel, HdpModel\n\nfrom scipy import signal\n\n\ntry:\n    _create_unverified_https_context = ssl._create_unverified_context\nexcept AttributeError:\n    pass\nelse:\n    ssl._create_default_https_context = _create_unverified_https_context\n\nnltk.download('punkt')\nnltk.download('averaged_perceptron_tagger')\nnltk.download('vader_lexicon')\n\n[nltk_data] Downloading package punkt to\n[nltk_data]     /Users/janinedevera/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     /Users/janinedevera/nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n[nltk_data] Downloading package vader_lexicon to\n[nltk_data]     /Users/janinedevera/nltk_data...\n[nltk_data]   Package vader_lexicon is already up-to-date!\n\n\nTrue\n\n\n\nos.chdir('portfolio/migration-sentiment-monitor/src/main/')\n\n\nrt_texts = (\n    pd.read_csv('raw.csv', header=None)\n    .set_axis(['title', 'date', 'text', 'link'], axis=1)\n    .dropna(subset=['text'])\n    .drop_duplicates(subset='link', keep='last')\n    .reset_index(drop=True)\n)\n\n\n# calculate sentiment scores\nsia = SentimentIntensityAnalyzer()\n\nresults = [sia.polarity_scores(x) for x in rt_texts['text']]\nsentiment = pd.DataFrame.from_dict(results)\n\nsentiment_df = pd.concat([rt_texts, sentiment], axis=1)\nsentiment_df\n\n\n\n\n\n\n\n\ntitle\ndate\ntext\nlink\nneg\nneu\npos\ncompound\n\n\n\n\n0\nFact Check: Widely shared English Channel fish and migrant claims are false\n11-Jul-24\nAll fish in the English Channel do not belong to the European Union, just as Britain does not have sole responsibility for people found in the sea...\nhttps://www.reuters.com/fact-check/widely-shared-english-channel-fish-migrant-claims-are-false-2024-07-11/\n0.009\n0.893\n0.098\n0.9972\n\n\n1\nSpain's far right threatens to exit regional coalitions over young migrant plan\n11-Jul-24\nMADRID, July 11 (Reuters) - Spanish far-right party Vox has threatened to bring down coalition governments with the centre-right People's Party in...\nhttps://www.reuters.com/world/europe/spains-far-right-threatens-exit-regional-coalitions-over-migrant-plan-2024-07-11/\n0.046\n0.838\n0.116\n0.9858\n\n\n2\nSlovak PM Fico's party likely to remain out of EU parliament alliances\n11-Jul-24\nJuly 11 (Reuters) - Slovak Prime Minister Robert Fico said on Thursday his ruling party SMER-SSD would stay out of the Socialists and Democrats (S...\nhttps://www.reuters.com/world/europe/slovak-pm-ficos-party-likely-remain-out-eu-parliament-alliances-2024-07-11/\n0.051\n0.829\n0.120\n0.9718\n\n\n3\nHousing crisis in Spain's cities drives rise in homelessness as tourism booms\n11-Jul-24\nMADRID, July 11 (Reuters) - Francisco Carrillo sobbed with relief as he lay on the bed in his new apartment in Madrid provided by a charity after ...\nhttps://www.reuters.com/world/europe/housing-crisis-spains-cities-drives-rise-homelessness-tourism-booms-2024-07-11/\n0.063\n0.864\n0.073\n0.8751\n\n\n4\nPoland says entry of trucks from Belarus slowed by sanctions\n11-Jul-24\nWARSAW, July 10 (Reuters) - The passage of trucks over the border into Poland from Belarus has been slowed by new sanctions, a Polish customs spok...\nhttps://www.reuters.com/world/europe/poland-says-entry-trucks-belarus-slowed-by-sanctions-2024-07-10/\n0.049\n0.929\n0.022\n-0.5082\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n1724\nIndia sends 100 antitrust queries for Reliance, Disney $8.5 bln merger, sources say\n22-Jul-24\nNEW DELHI, July 22 (Reuters) - India's antitrust body has asked Reliance Industries and Walt Disney around 100 questions linked to their $8.5 bill...\nhttps://www.reuters.com/markets/deals/india-sends-100-antitrust-queries-reliance-disney-85-bln-merger-sources-say-2024-07-22/\n0.010\n0.911\n0.079\n0.9713\n\n\n1725\nStocks firm, bitcoin loses some oomph as Biden steps down\n22-Jul-24\nLONDON, July 22 (Reuters) - Global shares steadied on Monday, after President Joe Biden's decision to bow out of the election race at the weekend ...\nhttps://www.reuters.com/markets/global-markets-wrapup-1-2024-07-22/\n0.068\n0.837\n0.096\n0.9673\n\n\n1726\nSouth African rand stable, inflation data in focus\n22-Jul-24\nJOHANNESBURG, July 22 (Reuters) - The South African rand was stable in early trade on Monday as investors await inflation data later this week for...\nhttps://www.reuters.com/markets/south-african-rand-stable-inflation-data-focus-2024-07-22/\n0.033\n0.890\n0.078\n0.8313\n\n\n1727\nTake Five: Feeling the heat\n22-Jul-24\nJuly 19 (Reuters) - There is rarely a dull moment in markets and the week to come will be no exception, with make-or-break U.S. inflation data and...\nhttps://www.reuters.com/business/take-five/global-markets-themes-graphic-2024-07-19/\n0.090\n0.791\n0.119\n0.9822\n\n\n1728\nStocks fall as global cyber outage weighs; dollar, yields rise\n19-Jul-24\nNEW YORK, July 19 (Reuters) - World stock indexes fell on Friday as a global cyber outage rattled investors by disrupting operations across multip...\nhttps://www.reuters.com/markets/global-markets-wrapup-1-2024-07-19/\n0.050\n0.902\n0.048\n-0.0772\n\n\n\n\n1729 rows × 8 columns\n\n\n\n\n# date format\nsentiment_df['date'] = sentiment_df['date'].apply(lambda x: datetime.strptime(x, \"%d-%b-%y\"))\nprint(f'Earliest: {sentiment_df[\"date\"].min()}')\nprint(f'Latest: {sentiment_df[\"date\"].max()}')\n\nEarliest: 2023-06-08 00:00:00\nLatest: 2024-07-22 00:00:00\n\n\n\n# average daily sentiment scores\ndaily = (\n    sentiment_df[['date', 'neg', 'neu', 'pos', 'compound']]\n    .groupby(['date']).mean()\n    .reset_index()\n)\n#daily = daily[daily['date'].dt.year &gt;= 2024]\n\n\n# check results\nresults = sentiment_df[sentiment_df['date'] == '2024-02-09']\npd.options.display.max_colwidth = 150\nprint(results['link'])\n\n615                                        https://www.reuters.com/world/uk/london-police-say-chemical-attacker-presumed-dead-2024-02-09/\n616                                   https://www.reuters.com/world/europe/greece-raise-investment-price-golden-visas-pm-says-2024-02-09/\n618    https://www.reuters.com/world/asia-pacific/chinas-new-year-travel-rush-kicks-into-high-gear-country-adds-record-number-2024-02-09/\n619                          https://www.reuters.com/world/guatemala-maintain-taiwan-ties-despite-seeking-greater-china-trade-2024-02-08/\nName: link, dtype: object\n\n\n\n# plot daily sentiment scores\nfig = go.Figure()\nfig.add_trace(go.Scatter(\n    x=daily['date'],\n    y=daily['compound'],\n    mode='lines',\n    marker=dict(size=2, color='black'),\n    name='Sine'\n))\n\nfig.add_trace(go.Scatter(\n    x=daily['date'],\n    y=signal.savgol_filter(daily['compound'],\n                           53, # window size used for filtering\n                           3), # order of fitted polynomial\n    mode='markers',\n    marker=dict(\n        size=6,\n        color='mediumpurple',\n        symbol='triangle-up'\n    ),\n    name='Savitzky-Golay'\n))\n\n\nfig.show()\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n\nfig = px.line(daily, x='date', y='neu')\nfig.show()\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n\n# average monthly sentiment scores\nsentiment_df['month'] = sentiment_df['date'].dt.to_period('M')\n\nmonthly = (\n    sentiment_df[['month', 'neg', 'neu', 'pos', 'compound']]\n    .groupby(['month']).mean()\n    .reset_index()\n)\n\nmonthly['month'] = monthly['month'].dt.to_timestamp()\n\n\nSentiment across region\n\n# sentiment scores by region\nregions = ['Africa', 'America', 'Asia', 'Europe', 'Middle East']\n\nfor region in regions:\n    sentiment_df['region'] = 0\n\nfor region in regions:\n    sentiment_df[region] = sentiment_df['text'].apply(lambda x: 1 if region.lower() in x.lower() else 0)\n\n\nregions_long = sentiment_df.melt(id_vars=['date', 'month', 'neu', 'pos', 'neg', 'compound'], value_vars=regions, \n                                      var_name='region', value_name='value')\nregions_long = regions_long[regions_long['value'] == 1]\n\n\nregions_df = (\n    regions_long[['month', 'region', 'neg', 'neu', 'pos', 'compound']]\n    .groupby(['month', 'region']).mean()\n    .reset_index()\n)\nregions_df['month'] = regions_df['month'].dt.to_timestamp()\n\n\nmean = regions_df.groupby('month')['compound'].mean()\nmean\n\nmonth\n2023-06-01   -0.152190\n2023-07-01   -0.051451\n2023-08-01   -0.427097\n2023-09-01   -0.282448\n2023-10-01   -0.091747\n2023-11-01    0.108743\n2023-12-01    0.104129\n2024-01-01   -0.285360\n2024-02-01    0.101462\n2024-03-01   -0.318995\n2024-04-01    0.062334\n2024-05-01   -0.001106\n2024-06-01   -0.165270\n2024-07-01    0.286218\nName: compound, dtype: float64\n\n\n\nfor month, mean_value in mean.items():\n    print(month, mean_value)\n\n2023-06-01 00:00:00 -0.15218990274093724\n2023-07-01 00:00:00 -0.05145119696969695\n2023-08-01 00:00:00 -0.4270970757575758\n2023-09-01 00:00:00 -0.28244783172147003\n2023-10-01 00:00:00 -0.0917471670193338\n2023-11-01 00:00:00 0.10874287820512821\n2023-12-01 00:00:00 0.10412897652211336\n2024-01-01 00:00:00 -0.28536018604651164\n2024-02-01 00:00:00 0.10146193195108984\n2024-03-01 00:00:00 -0.31899534640522875\n2024-04-01 00:00:00 0.062334151515151516\n2024-05-01 00:00:00 -0.0011063031241204558\n2024-06-01 00:00:00 -0.16527019421101774\n2024-07-01 00:00:00 0.2862179721019721\n\n\n\nmonth_ave = regions_df[regions_df['month'] == '2024-07-01']\nlen_region = len(month_ave['region'].unique())-1\nlen_region\n\n4\n\n\n\nmonth_ave\n\n\n\n\n\n\n\n\nmonth\nregion\nneg\nneu\npos\ncompound\n\n\n\n\n65\n2024-07-01\nAfrica\n0.074619\n0.851381\n0.073762\n0.136010\n\n\n66\n2024-07-01\nAmerica\n0.073778\n0.834407\n0.091889\n0.272485\n\n\n67\n2024-07-01\nAsia\n0.074333\n0.821667\n0.104000\n0.504033\n\n\n68\n2024-07-01\nEurope\n0.065455\n0.842886\n0.091636\n0.374682\n\n\n69\n2024-07-01\nMiddle East\n0.088400\n0.800000\n0.111800\n0.143880\n\n\n\n\n\n\n\n\nfig = px.bar(regions_df, x='month', y='compound', color='region', barmode='group')\nfig.show()\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n\n\nTopic models\n\n# pre-process keep stopwords\ndef preprocess_texts(texts):\n    def remove_stops_digits(tokens):\n        token_list =  [token.lower() for token in tokens if token not in punctuation and token.isdigit() == False]\n        processed_text = ' '.join(token_list)\n        return processed_text\n    return [remove_stops_digits(word_tokenize(text)) for text in texts]\n\n\n# pre-process remove stopwords\ndef preprocess_texts(texts):\n    eng_stopwords = set(stopwords.words(\"english\"))\n    def remove_stops_digits(tokens):\n        token_list =  [token.lower() for token in tokens if token not in eng_stopwords and token not in punctuation and token.isdigit() == False]\n        processed_text = ' '.join(token_list)\n        return processed_text\n    return [remove_stops_digits(word_tokenize(text)) for text in texts]\n\n\n# pre-processed texts to spacy\nnlp = spacy.load('en_core_web_sm')\n\nsentiment_df['text_clean'] = preprocess_texts(sentiment_df['text'])\nsentiment_df['docs'] = sentiment_df['text_clean'].apply(lambda x: nlp(x))\n\n\n# pre-process v2 \nnlp.Defaults.stop_words |= {'say', 'tell', 'reuters', 'year', 'tab', 'new', 'people'}\nexclude_words = ['say', 'tell', 'reuters', 'year', 'tab', 'new', 'people']\n\ntokens = []\n\nfor text in nlp.pipe(sentiment_df['text']):\n    clean = [token.lemma_.lower() for token in text if not token.is_stop and token.is_alpha and token.lemma_.lower() not in exclude_words]\n    tokens.append(clean)\n\n\nsentiment_df['tokens'] = tokens\n\n\n# sentiment_df = sentiment_df.drop(['topic'], axis=1)\n\n\nsentiment_df.to_pickle('raw_topics.pkl')\n\n\npd.read_pickle('raw_topics.pkl')\n\n\n\n\n\n\n\n\ntitle\ndate\ntext\nlink\nneg\nneu\npos\ncompound\nmonth\nregion\nAfrica\nAmerica\nAsia\nEurope\nMiddle East\ntokens\n\n\n\n\n0\nFact Check: Widely shared English Channel fish and migrant claims are false\n2024-07-11\nAll fish in the English Channel do not belong to the European Union, just as Britain does not have sole responsibility for people found in the sea...\nhttps://www.reuters.com/fact-check/widely-shared-english-channel-fish-migrant-claims-are-false-2024-07-11/\n0.009\n0.893\n0.098\n0.9972\n2024-07\n0\n0\n0\n0\n1\n0\n[fish, english, channel, belong, european, union, britain, sole, responsibility, find, sea, britain, france, contrary, widely, share, claim, socia...\n\n\n1\nSpain's far right threatens to exit regional coalitions over young migrant plan\n2024-07-11\nMADRID, July 11 (Reuters) - Spanish far-right party Vox has threatened to bring down coalition governments with the centre-right People's Party in...\nhttps://www.reuters.com/world/europe/spains-far-right-threatens-exit-regional-coalitions-over-migrant-plan-2024-07-11/\n0.046\n0.838\n0.116\n0.9858\n2024-07\n0\n1\n0\n0\n1\n0\n[madrid, july, spanish, far, right, party, vox, threaten, bring, coalition, government, centre, right, party, region, protest, agreement, transfer...\n\n\n2\nSlovak PM Fico's party likely to remain out of EU parliament alliances\n2024-07-11\nJuly 11 (Reuters) - Slovak Prime Minister Robert Fico said on Thursday his ruling party SMER-SSD would stay out of the Socialists and Democrats (S...\nhttps://www.reuters.com/world/europe/slovak-pm-ficos-party-likely-remain-out-eu-parliament-alliances-2024-07-11/\n0.051\n0.829\n0.120\n0.9718\n2024-07\n0\n0\n0\n0\n1\n0\n[july, slovak, prime, minister, robert, fico, thursday, rule, party, smer, ssd, stay, socialists, democrats, group, european, union, parliament, i...\n\n\n3\nHousing crisis in Spain's cities drives rise in homelessness as tourism booms\n2024-07-11\nMADRID, July 11 (Reuters) - Francisco Carrillo sobbed with relief as he lay on the bed in his new apartment in Madrid provided by a charity after ...\nhttps://www.reuters.com/world/europe/housing-crisis-spains-cities-drives-rise-homelessness-tourism-booms-2024-07-11/\n0.063\n0.864\n0.073\n0.8751\n2024-07\n0\n0\n0\n0\n1\n0\n[madrid, july, francisco, carrillo, sob, relief, lie, bed, apartment, madrid, provide, charity, sleep, rough, backroom, theatre, old, pensioner, f...\n\n\n4\nPoland says entry of trucks from Belarus slowed by sanctions\n2024-07-11\nWARSAW, July 10 (Reuters) - The passage of trucks over the border into Poland from Belarus has been slowed by new sanctions, a Polish customs spok...\nhttps://www.reuters.com/world/europe/poland-says-entry-trucks-belarus-slowed-by-sanctions-2024-07-10/\n0.049\n0.929\n0.022\n-0.5082\n2024-07\n0\n0\n0\n0\n1\n0\n[warsaw, july, passage, truck, border, poland, belarus, slow, sanction, polish, custom, spokesperson, wednesday, minsk, warsaw, stop, allow, lorry...\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n1724\nIndia sends 100 antitrust queries for Reliance, Disney $8.5 bln merger, sources say\n2024-07-22\nNEW DELHI, July 22 (Reuters) - India's antitrust body has asked Reliance Industries and Walt Disney around 100 questions linked to their $8.5 bill...\nhttps://www.reuters.com/markets/deals/india-sends-100-antitrust-queries-reliance-disney-85-bln-merger-sources-say-2024-07-22/\n0.010\n0.911\n0.079\n0.9713\n2024-07\n0\n0\n0\n1\n0\n0\n[delhi, july, india, antitrust, body, ask, reliance, industries, walt, disney, question, link, billion, india, medium, asset, merger, include, det...\n\n\n1725\nStocks firm, bitcoin loses some oomph as Biden steps down\n2024-07-22\nLONDON, July 22 (Reuters) - Global shares steadied on Monday, after President Joe Biden's decision to bow out of the election race at the weekend ...\nhttps://www.reuters.com/markets/global-markets-wrapup-1-2024-07-22/\n0.068\n0.837\n0.096\n0.9673\n2024-07\n0\n0\n0\n1\n1\n0\n[london, july, global, share, steady, monday, president, joe, biden, decision, bow, election, race, weekend, inject, degree, optimism, market, sur...\n\n\n1726\nSouth African rand stable, inflation data in focus\n2024-07-22\nJOHANNESBURG, July 22 (Reuters) - The South African rand was stable in early trade on Monday as investors await inflation data later this week for...\nhttps://www.reuters.com/markets/south-african-rand-stable-inflation-data-focus-2024-07-22/\n0.033\n0.890\n0.078\n0.8313\n2024-07\n0\n1\n0\n0\n0\n0\n[johannesburg, july, south, african, rand, stable, early, trade, monday, investor, await, inflation, datum, later, week, hint, country, future, in...\n\n\n1727\nTake Five: Feeling the heat\n2024-07-22\nJuly 19 (Reuters) - There is rarely a dull moment in markets and the week to come will be no exception, with make-or-break U.S. inflation data and...\nhttps://www.reuters.com/business/take-five/global-markets-themes-graphic-2024-07-19/\n0.090\n0.791\n0.119\n0.9822\n2024-07\n0\n0\n0\n0\n1\n0\n[july, rarely, dull, moment, market, week, come, exception, break, inflation, datum, tough, question, international, financing, ukraine, backdrop,...\n\n\n1728\nStocks fall as global cyber outage weighs; dollar, yields rise\n2024-07-19\nNEW YORK, July 19 (Reuters) - World stock indexes fell on Friday as a global cyber outage rattled investors by disrupting operations across multip...\nhttps://www.reuters.com/markets/global-markets-wrapup-1-2024-07-19/\n0.050\n0.902\n0.048\n-0.0772\n2024-07\n0\n0\n0\n0\n0\n0\n[york, july, world, stock, index, fall, friday, global, cyber, outage, rattle, investor, disrupt, operation, multiple, industry, dollar, climb, tr...\n\n\n\n\n1729 rows × 16 columns\n\n\n\n\ndictionary = Dictionary(sentiment_df['tokens'])\ndictionary.filter_extremes(no_below=3, no_above=0.5)\n\n\ncorpus = [dictionary.doc2bow(doc) for doc in sentiment_df['tokens']]\n\n\ntopics = []\nscore = []\nfor i in range(1,10,1):\n   lda_model = LdaMulticore(corpus=corpus, id2word=dictionary, iterations=10, num_topics=i, workers = 4, passes=5, random_state=100)\n   cm = CoherenceModel(model=lda_model, corpus=corpus, dictionary=dictionary, coherence='u_mass')\n   topics.append(i)\n   score.append(cm.get_coherence())\n   \n_=plt.plot(topics, score)\n_=plt.xlabel('Number of Topics')\n_=plt.ylabel('Coherence Score')\nplt.show()\n\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n\n\n\n\n\n\ntopics = []\nscore = []\nfor i in range(1,10,1):\n   lda_model = LdaMulticore(corpus=corpus, id2word=dictionary, iterations=10, num_topics=i, workers = 4, passes=5, random_state=100)\n   cm = CoherenceModel(model=lda_model, texts = sentiment_df['tokens'], corpus=corpus, dictionary=dictionary, coherence='c_v')\n   topics.append(i)\n   score.append(cm.get_coherence())\n   \n_=plt.plot(topics, score)\n_=plt.xlabel('Number of Topics')\n_=plt.ylabel('Coherence Score')\nplt.show()\n\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n\n\n\n\n\n\nlda_model = LdaMulticore(corpus=corpus, id2word=dictionary, num_topics=6, iterations=100, passes=50, random_state=100)\nlda_model\n\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n&lt;frozen importlib._bootstrap&gt;:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n\n\n&lt;gensim.models.ldamulticore.LdaMulticore at 0x31ffc4af0&gt;\n\n\n\nlda_model.print_topics(-1)\n\n[(0,\n  '0.009*\"britain\" + 0.008*\"worker\" + 0.007*\"sunak\" + 0.007*\"asylum\" + 0.006*\"rwanda\" + 0.006*\"work\" + 0.006*\"minister\" + 0.005*\"labour\" + 0.005*\"british\" + 0.005*\"million\"'),\n (1,\n  '0.011*\"boat\" + 0.008*\"sea\" + 0.007*\"rescue\" + 0.007*\"italy\" + 0.006*\"coast\" + 0.005*\"authority\" + 0.005*\"open\" + 0.005*\"island\" + 0.005*\"body\" + 0.005*\"africa\"'),\n (2,\n  '0.016*\"party\" + 0.012*\"eu\" + 0.011*\"right\" + 0.010*\"minister\" + 0.010*\"european\" + 0.009*\"election\" + 0.008*\"germany\" + 0.006*\"poland\" + 0.006*\"ukraine\" + 0.006*\"prime\"'),\n (3,\n  '0.019*\"biden\" + 0.016*\"trump\" + 0.012*\"president\" + 0.008*\"state\" + 0.007*\"election\" + 0.007*\"republican\" + 0.005*\"law\" + 0.005*\"policy\" + 0.005*\"texas\" + 0.005*\"court\"'),\n (4,\n  '0.031*\"border\" + 0.013*\"mexico\" + 0.010*\"asylum\" + 0.007*\"cross\" + 0.007*\"united\" + 0.007*\"number\" + 0.006*\"official\" + 0.006*\"crossing\" + 0.006*\"security\" + 0.006*\"states\"'),\n (5,\n  '0.007*\"open\" + 0.007*\"bank\" + 0.006*\"eu\" + 0.006*\"billion\" + 0.006*\"china\" + 0.006*\"market\" + 0.006*\"rate\" + 0.005*\"economy\" + 0.005*\"high\" + 0.005*\"growth\"')]\n\n\n\nsentiment_df['topic'] = [sorted(lda_model[corpus][text])[0][0] for text in range(len(sentiment_df['text']))]\n\n\nsentiment_df.to_pickle('raw_topics.pkl')\n\n\nsentiment_df.topic.value_counts()\n\ntopic\n0    776\n1    343\n2    243\n3    232\n4     88\n5     47\nName: count, dtype: int64\n\n\n\ntopic_dict = {\n    0: \"EU and UK asylum seekers\",\n    1: \"Refugees and migration by sea\",\n    2: \"European elections and far right parties\",\n    3: \"US elections and migration policies\",\n    4: \"US-Mexico border\",\n    5: \"Global economic outlook\"\n}\n\nsentiment_df['topic_name'] = sentiment_df['topic'].map(topic_dict)\nsentiment_df.to_pickle('raw_topics.pkl')\n\n\ntopic_df = (\n    sentiment_df[['topic', 'neg', 'neu', 'pos', 'compound']]\n    .groupby(['topic']).mean()\n    .reset_index()\n)\n\ntopic_df['topic_name'] = topic_df['topic'].map(topic_dict)\n\n\ntopic_df\n\n\n\n\n\n\n\n\ntopic\nneg\nneu\npos\ncompound\ntopic_name\n\n\n\n\n0\n0\n0.081098\n0.847515\n0.071415\n-0.113256\nUK asylum seekers\n\n\n1\n1\n0.080872\n0.852565\n0.066577\n-0.255222\nRefugees and migration by sea\n\n\n2\n2\n0.069956\n0.833368\n0.096636\n0.348848\nEuropean elections and far right parties\n\n\n3\n3\n0.070183\n0.847696\n0.082136\n0.056194\nUS elections\n\n\n4\n4\n0.043758\n0.884323\n0.072000\n0.282377\nUS-Mexico border\n\n\n5\n5\n0.049642\n0.858776\n0.091582\n0.692252\nGlobal economic outlook\n\n\n\n\n\n\n\n\nfig = px.bar(topic_df, x='compound', y='topic_name', orientation='h')\nfig.show()\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n\ntopic0 = sentiment_df[sentiment_df['topic'] == 0].copy()\n\n\nall_tokens = []\n\n# Iterate over each list in the 'tokens' column and extend all_tokens\nfor tokens_list in topic0['tokens']:\n    all_tokens.extend(tokens_list)\n\n\nall_tokens = [token for tokens_list in topic0['tokens'] for token in tokens_list]\n\n# Count frequencies of each token\ntoken_counts = Counter(all_tokens)\n\n# Alternatively, you can use pandas' value_counts() on the flattened Series\ntoken_counts_pd = pd.Series(all_tokens).value_counts()\n\n\nexclude_words = ['say', 'tell', 'reuters', 'year', 'tab', 'new', 'people', 'migrant', 'migration']\n\n\nnew_tokens = [i for i in all_tokens if i not in exclude_words]\n\n# Count frequencies of each token\ntoken_counts = Counter(new_tokens)\n\n# Alternatively, you can use pandas' value_counts() on the flattened Series\ntoken_counts_pd = pd.Series(new_tokens).value_counts()\n\n\ncounts_df = token_counts_pd[0:9].to_frame().reset_index()\ncounts_df.columns = ['token', 'count']\ncounts_df\n\n\n\n\n\n\n\n\ntoken\ncount\n\n\n\n\n0\ngovernment\n1199\n\n\n1\ncountry\n1178\n\n\n2\neu\n939\n\n\n3\nminister\n907\n\n\n4\nasylum\n861\n\n\n5\neuropean\n846\n\n\n6\nborder\n780\n\n\n7\nright\n762\n\n\n8\nparty\n729\n\n\n\n\n\n\n\n\ntoken_counts_pd[0:10]\n\ngovernment    1199\ncountry       1178\neu             939\nminister       907\nasylum         861\neuropean       846\nborder         780\nright          762\nparty          729\nitaly          724\nName: count, dtype: int64\n\n\n\nx=lda_model.show_topics(num_topics=5, num_words=15, formatted=False)\ntopics_words = [(tp[0], [wd[0] for wd in tp[1]]) for tp in x]\n\n#Below Code Prints Topics and Words\nfor topic,words in topics_words:\n    print(str(topic)+ \"::\"+ str(words))\nprint()\n\n#Below Code Prints Only Words \nfor topic,words in topics_words:\n    print(\" \".join(words))\n\n4::['border', 'mexico', 'asylum', 'cross', 'united', 'number', 'official', 'crossing', 'security', 'states', 'city', 'authority', 'state', 'mexican', 'president']\n1::['boat', 'sea', 'rescue', 'italy', 'coast', 'authority', 'open', 'island', 'body', 'africa', 'greece', 'mediterranean', 'libya', 'tunisia', 'police']\n0::['britain', 'worker', 'sunak', 'asylum', 'rwanda', 'work', 'minister', 'labour', 'british', 'million', 'seeker', 'plan', 'court', 'send', 'report']\n3::['biden', 'trump', 'president', 'state', 'election', 'republican', 'law', 'policy', 'texas', 'court', 'border', 'party', 'immigration', 'voter', 'candidate']\n2::['party', 'eu', 'right', 'minister', 'european', 'election', 'germany', 'poland', 'ukraine', 'prime', 'far', 'vote', 'leader', 'support', 'parliament']\n\nborder mexico asylum cross united number official crossing security states city authority state mexican president\nboat sea rescue italy coast authority open island body africa greece mediterranean libya tunisia police\nbritain worker sunak asylum rwanda work minister labour british million seeker plan court send report\nbiden trump president state election republican law policy texas court border party immigration voter candidate\nparty eu right minister european election germany poland ukraine prime far vote leader support parliament\n\n\n\nsampled_df = sentiment_df.groupby('topic').head(10)\nsampled_df['color'] = ['neg' if x &lt; 0 else 'pos' for x in sampled_df['compound']]\n\n/var/folders/rd/n9w0gpv53y72x5k9wk3hp63w0000gn/T/ipykernel_36917/813349552.py:2: SettingWithCopyWarning:\n\n\nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n\n\n\nfig = px.scatter(sampled_df, x='compound', y='topic',\n                 color = 'color', color_discrete_sequence=['#168578', '#B03C1F'])\nfig.add_vline(x=0, line_width=1, line_dash=\"dash\", line_color=\"black\")\nfig.update_traces(marker=dict(size=20, opacity=0.8, line=dict(width=2,\n                                        color='black')),\n                  selector=dict(mode='markers'))\nfig.show()\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json"
  }
]