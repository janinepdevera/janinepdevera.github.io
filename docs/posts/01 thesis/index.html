<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.340">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2023-05-13">
<meta name="description" content="I build a legal text classifier that correctly identifies up to 98% of paragraphs with potentially problematic provisions.">

<title>Janine De Vera - Using AI to Detect Anti-Competitive Legislation</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Janine De Vera</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../portfolio.html" rel="" target="">
 <span class="menu-text">Portfolio</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../datasets.html" rel="" target="">
 <span class="menu-text">Datasets</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../contact.html" rel="" target="">
 <span class="menu-text">Contact</span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools ms-auto">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Using AI to Detect Anti-Competitive Legislation</h1>
</div>

<div>
  <div class="description">
    <p>I build a legal text classifier that correctly identifies up to 98% of paragraphs with potentially problematic provisions.</p>
  </div>
</div>


<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">May 13, 2023</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<p>Competition is at the heart of consumer welfare. This is why in many countries, competition bodies assess new and existing policies for anti-competitive provisions. <strong>Competition Impact Assessment (CIA)</strong> studies are necessary for ensuring that regulations strike a balance between meeting sector-specific objectives and preserving a competitive market environment.</p>
<p>Ideally, most laws should be subjected to CIA and other types of regulatory assessments. But this is a time-consuming exercise: an <strong>initial review alone can take 2-4 months</strong>, according to an OECD<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> representative I spoke to. With hundreds of new laws and regulations proposed in any given country each year, the need for an <strong>efficient approach to competition impact assessment</strong> is great. Having myself worked in the Philippine Competition Commission for nearly 4 years, I have first-hand experience of how such undertakings can severely strain resources.</p>
<p>Recent years have shown that machine learning and AI, particularly large language models (LLM), can greatly aid in processing massive amounts of textual data. Legal texts are no exception, and this is precisely what I demonstrated in my master’s thesis. I developed a <strong>pre-screening tool</strong> that (1) identifies legislation containing potentially anti-competitive provisions, and (2) categorizes these provisions into different types of restrictions that need to be flagged to CIA proponents.</p>
<p>AI is no replacement for an expert’s thorough assessment, and when enacting policies with wide-ranging ramifications, human judgment must remain the final arbiter. But automation can be useful as a means of initial assessment, with <strong>only those having problematic provisions meriting further review</strong>. Workloads would be significantly reduced. The machine learning models I trained were able to <strong>correctly classify up to 98% of text with restrictive provisions</strong> and <strong>accurately assign up to 77% of provisions to their respective categories</strong>.</p>
<section id="data-a-corpus-of-legal-documents" class="level6">
<h6 class="anchored" data-anchor-id="data-a-corpus-of-legal-documents"><span class="second-color">Data: a corpus of legal documents</span></h6>
<p>For my models, I used a database of <strong>legislative documents</strong> in countries where a round of OECD CIA studies was conducted. In all, I gathered a corpus of 273 texts from 7 countries. Each unstructured PDF was parsed to extract paragraphs containing relevant textual information, resulting in a total of 7,335 unique paragraphs of which 2,104 have been manually labeled based on the 4 categories identified in the <a class="second-hover" href="https://www.oecd.org/daf/competition/oecd-competition-assessment-checklist-en.pdf">CIA checklist</a> of the OECD:</p>
<table class="table">
<colgroup>
<col style="width: 25%">
<col style="width: 26%">
<col style="width: 48%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;"></th>
<th style="text-align: center;">Category</th>
<th style="text-align: center;">Sub-categories</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">A</td>
<td style="text-align: center;">Limits the number or range of suppliers</td>
<td style="text-align: center;">Exclusivity rights, licenses and permits, cost of entry, geographical barriers</td>
</tr>
<tr class="even">
<td style="text-align: center;">B</td>
<td style="text-align: center;">Limits the ability of suppliers to compete</td>
<td style="text-align: center;">Price regulation, advertising restrictions, unduly strict quality standards, cost of production</td>
</tr>
<tr class="odd">
<td style="text-align: center;">C</td>
<td style="text-align: center;">Reduces the incentive of suppliers to compete</td>
<td style="text-align: center;">Self- or co-regulatory regimes, publishing of sensitive business information, exemption from antitrust laws</td>
</tr>
<tr class="even">
<td style="text-align: center;">D</td>
<td style="text-align: center;">Limits the choices and information available to customers</td>
<td style="text-align: center;">Buyer-seller information asymmetry, consumer switching costs</td>
</tr>
</tbody>
</table>
<p>Category D is lumped together with other miscellaneous provisions into a new category called <em>Others</em>. If a paragraph does not relate to any of the 4 categories, it is assigned a label of <em>None</em>. A good amount of processing had to be conducted to prepare the data for modeling. I discuss the data preparation step and provide an sample of the labeled dataset in <a class="second-hover" href="../../datasets/02 thesis/index.html">this post</a>.</p>
<!-- ###### [The problem: automation of document classification]{.second-color}

Automating the initial screening of documents for CIA can be divided into two parts. First is identifying whether a law has provisions with potential anti-competitive effects. This is a yes or no question that can be framed as a binary classification task. Second: distinguishing between multiple categories of restrictions in laws that have been flagged in the first step. I treat this as a multi-class task. -->
</section>
<section id="binary-classification-is-the-law-potentially-anti-competitive" class="level6">
<h6 class="anchored" data-anchor-id="binary-classification-is-the-law-potentially-anti-competitive"><span class="second-color">Binary classification: is the law potentially anti-competitive?</span></h6>
<p>Automating the initial screening of documents for CIA can be divided into two parts. The first task is identifying whether a law has provisions with potential anti-competitive effects. This is a yes or no question that I framed as a binary classification problem. To get the outcome variable, all four categories were encoded as <u><em>with restrictions</em></u> and none as <u><em>no restrictions</em></u>.</p>
<p>From here, I created a text classification pipeline starting with extracting <em>features</em> from the text. In NLP, <strong>feature extraction</strong> involves representing raw text as numerical values that can be understood and processed by machines. There are two main approaches to this: <strong>count-based</strong> and <strong>distributed</strong> representations. Count-based features rely on the <strong>frequency</strong> of word appearance in a document or corpus, while distributed representations or <strong>word embeddings</strong> are n-dimensional vectors that capture the <strong>semantic and syntactic</strong> characteristics of words. I used unigrams and n-grams for count-based representations<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>, and GloVe and Legal Word2Vec for word embeddings<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>.</p>
<p>I used these input features to train and validate machine learning models under different specifications, with logistic regression as benchmark and <strong>support vector machine (SVM)</strong> as the main model. Logistic regression is a widely popular technique for classification tasks because it is easy to implement and interpret. The model assumes a linear relationship among features and calculates the probability of an observation belonging to a certain category based on the appearance of these features. SVMs are more versatile and are capable of understanding non-linear relationships in data.</p>
<p>The figure below shows the results from the binary classifiers. Model predictions are represented as a <strong>confusion matrix</strong>. The upper right quadrant shows the <strong>number of paragraphs with restrictions correctly classified by the model</strong> (true positives), while the lower left quadrant shows the <strong>number of paragraphs without restrictions correctly classified by the model</strong> (true negatives).</p>
<p>Aside from maximizing these two metrics, it is also important to minimize to the lower right quadrant which shows <strong>false negatives</strong>. A high number of false negatives means that laws will be inaccurately tagged as <u>not</u> problematic when they in fact contain provisions that could restrict competition. For this particular use case, documents that are classified as <em>no restrictions</em> will not be further reviewed by experts. If paragraphs with restrictions are inaccurately classified, potential anti-competitive issues within the legislation are missed and cannot be properly addressed.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/01 binary.png" class="img-fluid figure-img" style="width:90.0%"></p>
</figure>
</div>
<p>The best binary classifiers<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> correctly can <strong>identify 94 to 98%</strong><a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a> <strong>of paragraphs with potentially anti-competitive provisions</strong>.</p>
</section>
<section id="multi-class-classification-what-kind-of-anti-competitive-provisions" class="level6">
<h6 class="anchored" data-anchor-id="multi-class-classification-what-kind-of-anti-competitive-provisions"><span class="second-color">Multi-class classification: what kind of anti-competitive provisions?</span></h6>
<p>The second part of the screening process involves <strong>categorizing paragraphs based on the type of restrictions present in the text</strong> – essentially a multi-class classification task<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a>. This function is beneficial to practitioners in cases where specific types of anti-competitive provisions need to be prioritized.</p>
<p>The same input features (unigrams, n-grams, GloVe, Legal Word2Vec) were applied to the multi-class equivalent of the logistic and SVM models<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a>. The results were evaluated using <strong>precision</strong><a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a> (the proportion of true positives out of all predicted positives) and <strong>recall</strong><a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a> (the proportion of true positives out of all actual positives). As with the binary classifiers, it is important to <strong>minimize false negatives.</strong> This is demonstrated in <strong>high recall scores</strong>.</p>
<p>The figure below shows the performance of the best classifiers. Overall, the models were able to <strong>correctly categorize the type of restrictions in up to 77% of texts</strong>. However, it is noticeable that the performance varies across categories. Classifiers were able to accurately identify up to <strong>80% of paragraphs belonging to category A</strong>, and up to <strong>68% of paragraphs belonging to category B</strong>. The subpar performance for categories C and Others can be attributed to data imbalance, which I discuss in more detail in the <a class="second-hover" href="../../datasets/02 thesis/index.html">data post</a>. Overall, the performance of the multi-class models are comparable with similar legal text classification studies<a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/02 multi.png" class="img-fluid figure-img" style="width:75.0%"></p>
</figure>
</div>
</section>
<section id="semantic-similarity-approach-when-labels-are-not-available" class="level6">
<h6 class="anchored" data-anchor-id="semantic-similarity-approach-when-labels-are-not-available"><span class="second-color">Semantic similarity approach: when labels are not available</span></h6>
<p>The performance of classification models can be improved by collecting more labeled observations. In many cases, the most precise way of gathering data is through manual annotation of documents. However, this approach is not always practical and feasible.</p>
<p>As an alternative, I conducted an experiment that explores <strong>semantic textual similarity (STS)</strong>. This is an <strong>unsupervised learning</strong> approach that minimizes reliance on labeled data. STS involves <strong>comparing the representations or embeddings of two pieces of text</strong> using a distance measure or a <strong>similarity score</strong>. The higher the score, the more likely it is that a text pair is related.</p>
<p>To implement this, I created <strong>verbalized labels</strong>. Instead of using a categorical variable as in typical classification tasks, key words and phrases were assigned to each label. The verbalized labels were taken from the OECD’s description of the four potential restrictions in their <a class="second-hover" href="https://www.oecd.org/en/publications/competition-assessment-toolkit-principles-version-4-0-volume-i_5f9fa6ca-en.html">CIA toolkit</a>. All paragraphs were paired to each of the verbalized labels, and similarity scores were calculated. An arbitrary <strong>threshold was set to determine whether the text can be classified into a particular label</strong>.</p>
<p>The embeddings used to calculate similarity scores were derived from variants of the widely popular <strong>Bidirectional Encoder Representations from Transformers or</strong> <a class="second-hover" href="https://arxiv.org/pdf/1810.04805">BERT</a>. The first model applied pre-trained Sentence BERT (SBERT) embeddings. In the second model, the embeddings were improved using a technique called <strong>domain adaptive pre-training</strong>. This step introduces additional information specific to the <em>legal</em> text corpus, as opposed to relying on the more generic embeddings from base BERT.</p>
<p>The figure below shows the results of this threshold-based classification using STS. As expected, the model with domain adaptive pre-training was able to correctly classify more paragraphs with restrictions. The model has a <strong>weighted average recall of 81% across all categories</strong> – it is able to correctly classify the type of restrictions in up to 81% of texts. It also outperforms the previous models in the underrepresented categories, C and Others.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/04 sbert-results.png" class="img-fluid figure-img" style="width:75.0%"></p>
</figure>
</div>
<p>The results of this study demonstrate how AI can benefit the legal profession. The applications of a text classifier extend beyond competition regulation. The same principle can be used to detect provisions relating to any number of policy outcomes, from climate to migration. Through the creative application of machine and deep learning models, the time spent on repetitive tasks can be greatly reduced, allowing human minds to focus on deeper analytical work.</p>


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Organisation for Economic Co-operation and Development<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>In particular, a TF-IDF (term frequency inverse document frequency) matrix. Unigrams are single words, while n-grams are phrases that are 2 to 5 words in length.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>GloVe embeddings can be downloaded <a href="https://nlp.stanford.edu/projects/glove/">here </a> and Legal Word2Vec can be downloaded <a href="https://osf.io/qvg8s/">here</a>.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>More than 4,200 binary model specifications were trained and tested using different hyperparameter combinations. The best models were selected through a grid search algorithm.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>Given by the formula <span class="math inline">\(TP / (TP + FN)\)</span><a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>In multi-class problems, labels are mutually exclusive so only one label is assigned per text. In reality, there could be more than one label per document (a multi-label problem). But for demonstration purposes, I choose to the simpler multi-class specification.<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>Softmax and multi-class support vector machines<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p><span class="math inline">\(TP / (TP + FP)\)</span><a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9"><p><span class="math inline">\(TP / (TP + FN)\)</span><a href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10"><p>Such as <a href="https://arxiv.org/abs/2010.12871">Shaheen, Wohlgenannt, and Filtz (2020)</a> and <a href="https://ceur-ws.org/Vol-2826/T1-7.pdf"> Gao, et. al.&nbsp;(2020)</a>.<a href="#fnref10" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>